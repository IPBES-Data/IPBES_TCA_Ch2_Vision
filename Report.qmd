---
title: 'Report Assessment Ch2 Technology Visions'
subtitle: 'Data Management Report'
author:
  - name: 
        family: Krug
        given: Rainer M.    
        id: rmk
    orcid: 0000-0002-7490-0066
    email: Rainer.Krug@Senckenberg.de, Rainer@Krugs.de
    affiliation: 
      - name: Senckenberg
        city: Frankfurt (Main)
        url: https://www.senckenberg.de/en/institutes/sbik-f/
    roles: [author, editor]
abstract: > 
  A short description what this is about.
  This is not a tracditional abstract, but rather something else ...
license: "CC BY"
copyright: 
  holder: No idea
  year: 2024
citation: 
  type: report
  container-title: IPBES Data Management Report
  doi: XXXXXX
doi: XXXXXX
version: 0.0.1

format:
    html:
        toc: true
        toc-depth: 4
        toc_expand: true
        embed-resources: true
        code-fold: true
        code-summary: 'Show the code'
        grid:
            sidebar-width: 0px
            body-width: 4000px
            margin-width: 200px
            gutter-width: 1.5rem      

params:
    gdm_dir: !expr file.path("data", "gdm_dir")
    #
    st_vision: !expr paste(readLines(file.path("input", "ch2_technology", "search_terms", "vision.txt")), collapse = " ")
    st_technology: !expr paste(readLines(file.path("input", "ch2_technology", "search_terms", "technology.txt")), collapse = " ")
    st_marine: !expr paste(readLines(file.path("input", "ch2_technology", "search_terms", "marine.txt")), collapse = " ")
    #
    fn_sentiment_results: !expr file.path("input", "ch2_technology", "sentiment_results.rds")
    #
    st_case: !expr paste(readLines(file.path("..", "IPBES_TCA_Corpus", "input", "tca_corpus", "search terms", "case.txt")), collapse = " ")
    #
    pages_dir: !expr file.path(".", "data", "ch2_technology", "pages_complete")
    #
    corpus_complete_dir: !expr file.path(".", "data", "ch2_technology", "corpus_complete")
    corpus_dir: !expr file.path(".", "data", "ch2_technology", "corpus")
    corpus_authors_dir: !expr file.path("data", "ch2_technology", "corpus_authors")
    corpus_topics_dir: !expr file.path("data", "ch2_technology", "corpus_topics")
    #
    corpus_tca_dir: !expr file.path("..", "IPBES_TCA_Corpus", "data", "tca_corpus", "corpus")
    #
    fn_count: !expr file.path("data", "ch2_technology", "oa_count.rds")
    fn_ids_tech_in_tca: !expr file.path("data", "ch2_technology", "ids_tech_in_tca.rds")
    fn_sent_analysis_parquet: !expr file.path("data", "ch2_technology", "sent_analysis_technology.parquet")
    fn_random_sample_250: !expr file.path("data", "ch2_technology", "random_250_technology_in_tca.xlsx")
    fn_publications_over_time: !expr file.path("data", "ch2_technology", "publications_over_time.rds")
    #
    fn_sentiment_spatial_data: !expr file.path("data", "ch2_technology", "sentiment_spatial_data.rds")
    fn_sentiment_temporal_data: !expr file.path("data", "ch2_technology", "sentiment_temporal_data.rds")
    fn_sentiment_marine_temporal_data: !expr file.path("data", "ch2_technology", "sentiment_marine_temporal_data.rds")
    fn_marine_sentiment:  !expr file.path("data", "ch2_technology", "sentiment_marine_export.xlsx")
    fn_marine_sentiment_all:  !expr file.path("data", "ch2_technology", "sentiment_marine_all_export.xlsx")
    #
    fig_publications_over_time: !expr file.path("figures", "ch2_technology", "publications_over_time")
    #
    temporal_from: 1900
    min_count_sentiment_timeseries: 10

---

```{r}
#| label: setup
#| include: false

if (!exists("params")) {
    params <- rmarkdown::yaml_front_matter("Report.qmd")$params
}

build <- as.integer(readLines("buildNo"))
build <- build + 1
writeLines(as.character(build), "buildNo")

knitr::opts_chunk$set(message = NA)

library(openalexR)
library(arrow)
library(duckdb)
library(DBI)
library(dplyr)
library(ggplot2)
library(ggridges)
library(IPBES.R)
library(tictoc)

#####

get_count <- !file.exists(params$fn_count)
if (get_count) {
    oa_count <- list(
        timestamp = Sys.time()
    )
} else {
    oa_count <- readRDS(params$fn_count)
}

#####

source(file.path("R", "ch2_technology", "functions.R"))

```

## Working Title
IPBES_TCA_Ch2_technology

## Code repo

[Github - private](https://github.com/IPBES-Data/IPBES_TCA_Ch2_technology)

## Build No: `r build`

%The BuidNo is automatically increased by one each time the report is rendered. It is used to indicate different renderings when the version stays the same%.

## Introduction

All searches are done on all works in OpenAlex. The search in the TCA Corpus is not possibly at the moment, but we are working on it.


### The following steps will be done in documented in this report:

- [ ] Do asearch with `vision_st`, `params$st_technology`, and `params$st_vision AND params$st_technology` and determine the  number of hits
- [ ] Identify sub-fields (in topics) of hits
- [ ] Check filtering using sub-fields
- [ ] Should the complete `params$st_vision AND params$st_technology` be downloaded, or only a random subsets? Suggestiopn: 10 sets of 100 random works?

# Methods

## From OpenAlex directly
The search terms are based on the [shared google doc](https://docs.google.com/document/d/1_FmxYVhpv2Bu2Gbbxb7cWc49f3soFvc64Qau_x2RAqI){target=_blank}. They are cleaned up for the usage in [OpenAlex](https://openalex.org/){target=_blank}.

### OpenAlex Complete




```{r}
#| label: get_oa_count
#|

if (get_count) {
    oa_count$oa <- openalexR::oa_fetch(
        entity = "works",
        search = "",
        output = "list",
        count_only = TRUE,
        verbose = TRUE
    )$count
}
```

```{r}
#| label: get_oa_years
#|

if (get_count) {
    oa_count$oa_years <- openalexR::oa_fetch(
        group_by = "publication_year",
        output = "dataframe",
        verbose = TRUE
    ) |>
        dplyr::mutate(
            publication_year = as.integer(as.character(key_display_name)),
            key = NULL,
            key_display_name = NULL,
            p = count / sum(count)
        ) |>
        dplyr::arrange(publication_year) |>
        dplyr::mutate(
            p_cum = cumsum(p)
        ) |>
        dplyr::select(
            publication_year, 
            everything()
        )
}
```

### Vision

The search terms is [vision](input/ch2_technology/vision.txt){target=_blank}
Open Alex search.



```{r}
#| label: get_vision_count
#|

if (get_count) {
    oa_count$vision <- openalexR::oa_fetch(
        title_and_abstract.search = params$st_vision,
        count_only = TRUE,
        output = "list",
        verbose = TRUE
    )$count
}

```
```{r}
#| label: get_vision_years
#|

if (get_count) {
    oa_count$vision_years <- openalexR::oa_fetch(
        title_and_abstract.search = params$st_vision,
        group_by = "publication_year",
        output = "dataframe",
        verbose = TRUE
    ) |>
        dplyr::mutate(
            publication_year = as.integer(as.character(key_display_name)),
            key = NULL,
            key_display_name = NULL,
            p = count / sum(count)
        ) |>
        dplyr::arrange(publication_year) |>
        dplyr::mutate(
            p_cum = cumsum(p)
        ) |>
        dplyr::select(
            publication_year,
            everything()
        )
}
```



### Technology

The search terms is [technology](input/ch2_technology/technology.txt){target=_blank}
Open Alex search.



```{r}
#| label: get_technology_count
#|

if (get_count) {
    oa_count$technology <- openalexR::oa_fetch(
        title_and_abstract.search = compact(params$st_technology),
        count_only = TRUE,
        output = "list",
        verbose = TRUE
    )$count
}
```


```{r}
#| label: get_technology_years
#|

if (get_count) {
    oa_count$technology_years <- openalexR::oa_fetch(
        title_and_abstract.search = compact(params$st_technology),
        group_by = "publication_year",
        output = "dataframe",
        verbose = TRUE
    ) |>
        dplyr::mutate(
            publication_year = as.integer(as.character(key_display_name)),
            key = NULL,
            key_display_name = NULL,
            p = count / sum(count)
        ) |>
        dplyr::arrange(publication_year) |>
        dplyr::mutate(
            p_cum = cumsum(p)
        ) |>
        dplyr::select(
            publication_year,
            everything()
        )
}
```


### Vision AND technology
Open Alex search.

The search term is [vision](input/ch2_technology/vision.txt){target=_blank} AND [technology](input/ch2_technology/technology.txt){target=_blank}



```{r}
#| label: get_vision_technology_count
#|

if (get_count) {
    oa_count$vision_technology <- openalexR::oa_fetch(
        title_and_abstract.search = compact(paste0("(", params$st_vision, ") AND (", params$st_technology, ")")),
        output = "list",
        count_only = TRUE,
        verbose = TRUE
    )$count
}
```

```{r}
#| label: get_vision_technology_years
#|

if (get_count) {
    oa_count$vision_technology_years <- openalexR::oa_fetch(
        title_and_abstract.search = compact(paste0("(", params$st_vision, ") AND (", params$st_technology, ")")),
        group_by = "publication_year",
        output = "dataframe",
        verbose = TRUE
    ) |>
        dplyr::mutate(
            publication_year = as.integer(as.character(key_display_name)),
            key = NULL,
            key_display_name = NULL,
            p = count / sum(count)
        ) |>
        dplyr::arrange(publication_year) |>
        dplyr::mutate(
            p_cum = cumsum(p)
        ) |>
        dplyr::select(
            publication_year,
            everything()
        )
}
```


```{r}
#| label: get_vision_technology_subfield_years
#|
if (get_count) {
    oa_count$vision_technology_subfields <- openalexR::oa_query(
        title_and_abstract.search = compact(paste0("(", params$st_vision, ") AND (", params$st_technology, ")")),
        group_by = "primary_topic.subfield.id",
        verbose = TRUE
    ) |>
        openalexR::oa_request() |>
        dplyr::bind_rows() |>
        dplyr::arrange(key)

    ## clean up missing or wrong vision_technology_subfields$key_display_name
    need_cleaning <- is.na(oa_count$vision_technology_subfields$key_display_name) |
        !is.na(as.numeric(oa_count$vision_technology_subfields$key_display_name))

    fine <- !need_cleaning

    oa_count$vision_technology_subfields <- oa_count$vision_technology_subfields |>
        dplyr::filter(fine) |>
        dplyr::select(key, key_display_name) |>
        dplyr::distinct() |>
        merge(y = oa_count$vision_technology_subfields[need_cleaning, -2], by = "key") |>
        dplyr::bind_rows(oa_count$vision_technology_subfields[fine, ]) |>
        dplyr::group_by(key, key_display_name) |>
        dplyr::summarize(count = sum(count))
}
```



### Vision AND technology AND marine
Open Alex search.

The search term is [vision](input/ch2_technology/vision.txt){target=_blank} AND [technology](input/ch2_technology/technology.txt){target=_blank}



```{r}
#| label: get_vision_technology_marine_count
#|

if (get_count) {
    oa_count$vision_technology_marine <- openalexR::oa_fetch(
        title_and_abstract.search = compact(paste0("(", params$st_vision, ") AND (", params$st_technology, ") AND (", params$st_marine, ")")),
        output = "list",
        count_only = TRUE,
        verbose = TRUE
    )$count
}
```

```{r}
#| label: get_vision_technology_marine_years
#|

if (get_count) {
    oa_count$vision_technology_marine_years <- openalexR::oa_fetch(
        title_and_abstract.search = compact(paste0("(", params$st_vision, ") AND (", params$st_technology, ") AND (", params$st_marine, ")")),
        group_by = "publication_year",
        output = "dataframe",
        verbose = TRUE
    ) |>
        dplyr::mutate(
            publication_year = as.integer(as.character(key_display_name)),
            key = NULL,
            key_display_name = NULL,
            p = count / sum(count)
        ) |>
        dplyr::arrange(publication_year) |>
        dplyr::mutate(
            p_cum = cumsum(p)
        ) |>
        dplyr::select(
            publication_year,
            everything()
        )
}
```



```{r}
#| label: get_vision_technology_marine_ids
#|
if (get_count) {
    oa_count$vision_technology_marine_ids <- openalexR::oa_fetch(
        title_and_abstract.search = compact(paste0("(", params$st_vision, ") AND (", params$st_technology, ") AND (", params$st_marine, ")")),
        verbose = TRUE,
        output = "list",
    ) |>
        sapply(
            FUN = function(x) {
                x$id
            }
        ) |>
        unique()
}
```


Open Alex search.

The search term is [vision](input/ch2_technology/vision.txt){target=_blank} AND [technology](input/ch2_technology/technology.txt){target=_blank}

#### Count of Publications

```{r}
#| label: get_vision_technology_case_count
#| eval: false

# To long search string
if (get_count) {
    oa_count$vision_technology_case <- openalexR::oa_fetch(
        title_and_abstract.search = compact(paste0("(", params$st_vision, ") AND (", params$st_technology, ") AND (", params$st_case, ")")),
        output = "list",
        count_only = TRUE,
        verbose = TRUE
    )$count
}
```


```{r}
#| label: get_vision_technology_case_years
#|

if (get_count) {
    oa_count$vision_technology_case_years <- openalexR::oa_fetch(
        title_and_abstract.search = compact(paste0("(", params$st_vision, ") AND (", params$st_technology, ") AND (", params$st_case, ")")),
        group_by = "publication_year",
        output = "dataframe",
        verbose = TRUE
    ) |>
        dplyr::mutate(
            publication_year = as.integer(as.character(key_display_name)),
            key = NULL,
            key_display_name = NULL,
            p = count / sum(count)
        ) |>
        dplyr::arrange(publication_year) |>
        dplyr::mutate(
            p_cum = cumsum(p)
        ) |>
        dplyr::select(
            publication_year,
            everything()
        )
}
```


### Save the counts as `r params$fn_count`

```{r}
#| label: save_oa_count
#| 

if (get_count) {
    saveRDS(oa_count, params$fn_count)
}
```

## Download `technology AND vision` Corpus from OpenAlex

The corpus download will be stored in `ch2_technology/pages` and the arrow database in `data/ch2_technology/corpus_complete`. This one will be filtered with the TCA / G;obal Corpus and get the final name `data/ch2_technology/corpus`.

This is not on github!

The corpus can be read by running `corpus_read("data/ch2_technology/corpus")` which opens the database so that then it can be fed into a `dplyr` pipeline. After most `dplyr` functions, the actual data needs to be collected via `collect()`.

Only then is the actual data read!

Needs to be enabled by setting `eval: true` in the code block below.

### Download Complete Corpus

```{r}
#| label: get_technology_corpus
#| eval: false
#|

tic()

IPBES.R::corpus_download(
    pages_dir = file.path(".", "data", "ch2_technology", "pages"),
    title_and_abstract_search = compact(paste0("(", params$st_vision, ") AND (", params$st_technology, ")")),
    continue = TRUE,
    delete_pages_dir = FALSE,
    set_size = 2000,
    dry_run = TRUE,
    verbose = TRUE,
    mc_cores = 6
)

toc()
```

### Convert Technology Corpus to Parquet datase

The fields `author` and `topics` are serialized in the arrow database and need to be unserialized by using `unserialize_arrow()` on a dataset containing the two columns.

```{r}
#| label: convert_tca_corpus_arrow
#| eval: false
#| 

tic()

IPBES.R::corpus_pages_to_arrow(
    pages_dir = params$pages_dir,
    arrow_dir = params$corpus_complete_dir,
    continue = TRUE,
    delete_arrow_dir = FALSE,
    dry_run = FALSE,
    verbose = TRUE,
    mc_cores = 3
)
toc()
```

### Filter Corpus with TCA Corpus
```{r}
#| label: filter_corpus_with_tca
#| eval: false
#|

tic()

if (!file.exists(params$fn_ids_tech_in_tca)) {
    ids_technology <- IPBES.R::corpus_read(params$corpus_complete) |>
        dplyr::select(id) |>
        collect() |>
        unlist()

    ids_tca <- read_corpus(file.path("..", "IPBES_TCA_Corpus", "data", "tca_corpus", "corpus")) |>
        dplyr::select(id) |>
        collect() |>
        unlist()

    fn_ids_tech_in_tca <- ids_technology[ids_technology %in% ids_tca]

    rm(ids_technology, ids_tca)

    saveRDS(ids_tech_in_tca, params$fn_ids_tech_in_tca)

    IPBES.R::corpus_filter_ids(
        arrow_dir = params$corpus_complete_dir,
        arrow_filter_dir = params$corpus_dir,
        filter_ids = ids_tech_in_tca
    )

    rm(ids_tech_in_tca)
}

toc()
```



Check the number of dulicates before running this next block, and then verify the new corpus afterwards. RUN ONLY MANUALY!

```{r}
#| label: fix_duplicate_ids_TEMPORARY
#| eval: false
#|

ONLY RUN MANUALLY!!!!!!!!!!!!!!!!!!!!!!!

(read_corpus(params$corpus_dir) |> group_by(id) |> summarize(n = n()) |> filter(n > 1) |> collect() |> nrow()) / (corpus_read(params$corpus_dir) |> nrow())

years <- IPBES.R::corpus_read(params$corpus_dir) |>
    distinct(publication_year) |>
    collect() |>
    unlist() |>
    as.vector() |>
    sort()

lapply(
    years,
    function(y) {
        message("\nProcessing year: ", y)
        tic()
        dataset <- IPBES.R::corpus_read(params$corpus_dir) |>
            dplyr::filter(publication_year == y) |>
            dplyr::collect() |>
            group_by(id) |>
            slice_max(
                publication_year,
                n = 1,
                with_ties = FALSE,
                na_rm = TRUE
            )
        # unlink(
        #     file.path(params$corpus_dir, paste0("publication_year=", y)),
        #     recursive = TRUE,
        #     force = TRUE
        # )
        arrow::write_dataset(
            dataset = dataset,
            path = paste0(params$corpus_dir, "_deduplicated"),
            partitioning = c("publication_year", "set"),
            format = "parquet",
            existing_data_behavior = "overwrite"
        )
        toc()
    }
)

(read_corpus("./data/ch2_technology/corpus_deduplicated") |> group_by(id) |> summarize(n = n()) |> filter(n > 1) |> collect() |> nrow()) / (corpus_read("./data/ch2_technology/corpus_deduplicated") |> nrow())

rename corpora now 

NOW IF EVERYTHING IS OK, DELETE THE OLD CORPUS AND RENAME THE NEW ONE
```


 ## Export data for sentiment analysis


```{r}
#| label: export_sentiment_analysis
#|

if (!file.exists(params$fn_sent_analysis_parquet)) {
    corpus_read(params$corpus_dir) |>
        dplyr::select(id, publication_year, ab) |>
        arrow::write_parquet(params$fn_sent_analysis_parquet)
}

```

## Extract 250 random papers from `technology AND vision` in TCA Corpus
```{r}
#| label: extract_random_papers
#|

if (!file.exists(params$fn_random_sample_250)) {
    set.seed(14)
    read_corpus(params$corpus_dir) |>
        dplyr::select(id, doi, author_abbr, display_name, ab) |>
        dplyr::rename(abstract = ab, title = display_name) |>
        dplyr::collect() |>
        dplyr::slice_sample(n = 250) |>
        dplyr::mutate(
            abstract = substr(abstract, start = 1, stop = 5000)
        ) |>
        writexl::write_xlsx(path = params$fn_random_sample_250)
}
```


## Extract Authors

```{r}
#| label: authors_technology_corpus_data
#|

if (!dir.exists(params$corpus_authors_dir)) {
    con <- duckdb::dbConnect(duckdb::duckdb(), read_only = FALSE)

    corpus_read(params$corpus_dir) |>
        arrow::to_duckdb(table_name = "corpus", con = con) |>
        invisible()


    paste0(
        "CREATE VIEW corpus_unnest AS ",
        "SELECT  ",
        "corpus.id AS work_id,  ",
        "corpus.publication_year AS publication_year,  ",
        "UNNEST(author).au_id AS au_id,  ",
        "UNNEST(author).au_display_name AS au_display_name, ",
        "UNNEST(author).au_orcid AS au_orcid,  ",
        "UNNEST(author).author_position AS author_position,  ",
        "UNNEST(author).is_corresponding AS is_corresponding,  ",
        "UNNEST(author).au_affiliation_raw AS au_affiliation_raw,  ",
        "UNNEST(author).institution_id AS institution_id,  ",
        "UNNEST(author).institution_display_name AS institution_display_name,  ",
        "UNNEST(author).institution_ror AS institution_ror,  ",
        "UNNEST(author).institution_country_code AS institution_country_code,  ",
        "UNNEST(author).institution_type AS institution_type,  ",
        "UNNEST(author).institution_lineage AS institution_lineage  ",
        "FROM  ",
        "corpus "
    ) |> DBI::dbExecute(conn = con)

    paste0(
        "COPY ( ",
        "SELECT * FROM corpus_unnest ",
        ") TO '", params$corpus_authors_dir, "' ",
        "(FORMAT PARQUET, COMPRESSION 'SNAPPY', PARTITION_BY 'publication_year')"
    ) |>
        dbExecute(conn = con)

    duckdb::dbDisconnect(con, shutdown = TRUE)
}
```

## Publications over time
```{r}
#| label: publications_over_time_data
## | |

if (!file.exists(params$fn_publications_over_time)) {
    read_corpus(params$corpus_tca_dir) |>
        dplyr::select(publication_year) |>
        dplyr::arrange(publication_year) |>
        dplyr::collect() |>
        table() |>
        as.data.frame() |>
        dplyr::mutate(
            publication_year = as.integer(as.character(publication_year)),
            p = Freq / sum(Freq),
            p_cum = cumsum(p)
        ) |>
        dplyr::rename(
            count = Freq
        ) |>
        # oa complete
        dplyr::left_join(
            x = oa_count$oa_years,
            by = "publication_year",
            suffix = c("", "_tca")
        ) |>
        # oa vision
        dplyr::left_join(
            y = oa_count$vision_years,
            by = "publication_year",
            suffix = c("", "_vision")
        ) |>
        # oa technology
        dplyr::left_join(
            y = oa_count$technology_years,
            by = "publication_year",
            suffix = c("", "_technology")
        ) |>
        # oa vision technology
        dplyr::left_join(
            y = oa_count$vision_technology_years,
            by = "publication_year",
            suffix = c("", "_technology_vision")
        ) |>
        dplyr::rename(
            count_oa = count,
            p_oa = p,
            p_cum_oa = p_cum
        ) |>
    saveRDS(file = params$fn_publications_over_time)
}
```

```{r}
#| label: publications_over_time_figure

if (length(list.files(path = dirname(params$fig_publications_over_time), pattern = basename(params$fig_publications_over_time))) < 2) {
    sec_axi_fact <- 0.5e-5
    figure <- readRDS(params$fn_publications_over_time) |>
        dplyr::filter(publication_year >= params$temporal_from) |>
        ggplot2::ggplot() +
        #
        ggplot2::geom_bar(ggplot2::aes(x = publication_year, y = count_tca, fill = "Nmber of publications per year in TCA Corpus"), stat = "identity") +
        ggplot2::geom_line(ggplot2::aes(x = publication_year, y = p_cum_oa / sec_axi_fact, color = "Cumulative proportion OA Corpus"), size = 1.5) +
        ggplot2::geom_line(ggplot2::aes(x = publication_year, y = p_cum_tca / sec_axi_fact, color = "Cumulative proportion TCA Corpus"), size = 1.5) +
        ggplot2::geom_line(ggplot2::aes(x = publication_year, y = p_cum_vision / sec_axi_fact, color = "Cumulative proportion vision only corpus"), size = 1.5) +
        ggplot2::geom_line(ggplot2::aes(x = publication_year, y = p_cum_technology / sec_axi_fact, color = "Cumulative proportion technology only corpus"), size = 1.5) +
        ggplot2::geom_line(ggplot2::aes(x = publication_year, y = p_cum_technology_vision / sec_axi_fact, color = "Cumulative proportion Technology Corpus"), size = 1.5) +
        #
        ggplot2::scale_color_manual(
            values = c(
                "Cumulative proportion OA Corpus" = "#1f77b4",
                "Cumulative proportion TCA Corpus" = "black",
                "Cumulative proportion vision only corpus" = "#2ca02c",
                "Cumulative proportion technology only corpus" = "#d62728",
                "Cumulative proportion Technology Corpus" = "#9467bd"
            )
        ) +
        ggplot2::scale_fill_manual(
            values = c("Nmber of publications per year in TCA Corpus" = "lightgrey")
        ) +
        #
        ggplot2::scale_x_continuous(breaks = seq(params$temporal_from, 2030, 10)) +
        ggplot2::scale_y_continuous(
            "Proportion of publications",
            sec.axis = ggplot2::sec_axis(~ . * sec_axi_fact, name = "Cumulative proportion") # divide by 100 to scale back the secondary axis
        ) +
        ggplot2::labs(
            title = "Publications over time",
            x = "Year",
            y = "Number of publications"
        ) +
        ggplot2::theme_minimal() +
        ggplot2::theme(
            axis.text.y.right = ggplot2::element_text(color = "red"),
            legend.position = "inside", # Move the legend to the top left position
            legend.justification = c(0.1, 0.9), # Justify the legend to the top left position
            legend.background = ggplot2::element_rect(fill = "white", color = "black") # Add a white background to the legend
        )

    ggplot2::ggsave(
        paste0(params$fig_publications_over_time, ".pdf"),
        width = 12,
        height = 12,
        figure
    )
    ggplot2::ggsave(
        paste0(params$fig_publications_over_time, ".png"),
        width = 12,
        height = 12,
        figure
    )

    rm(figure, sec_axi_fact)
}
```


## Sentiment Analysis

```{r}
#| label: prepare_sent_results
#| eval: false
#| 

read.csv("input/ch2_technology/sent_analysis_technology_results_MD.csv") |>
    dplyr::group_by(id) |>
    dplyr::slice_min(
        order_by = row_number(), 
        n = 1
    ) |>
    saveRDS(file = params$fn_sentiment_results)

```

### Spatial


```{r}
#| label: sentiment_per_countries_data
#|

if (!file.exists(params$fn_sentiment_spatial_data)) {
    data <- corpus_read(params$corpus_authors_dir) |>
        dplyr::select(
            work_id,
            institution_country_code
        ) |>
        dplyr::filter(
            !is.na(institution_country_code)
        ) |>
        collect() |>
        mutate(
            iso3c = countrycode::countrycode(
                institution_country_code,
                origin = "iso2c",
                destination = "iso3c"
            ),
            institution_country_code = NULL
        ) |>
        dplyr::left_join(
            readRDS(params$fn_sentiment_results) |>
                dplyr::select(
                    work_id = id,
                    neg,
                    neu,
                    pos,
                    compound
                ) ,
            by = "work_id"
        ) |>
        dplyr::group_by(iso3c) |>
        dplyr::summarize(
            mean_neg = mean(neg, na.rm = TRUE),
            mean_neu = mean(neu, na.rm = TRUE),
            mean_pos = mean(pos, na.rm = TRUE),
            mean_compound = mean(compound, na.rm = TRUE),
            n = n()
        ) |>
        dplyr::arrange(
            dplyr::desc(mean_neg)
        ) |>
        # Filter out missing countries - only necessary as analysis not completed yet
        dplyr::filter(
            !is.nan(mean_neg)
        ) |>
        saveRDS(file = params$fn_sentiment_spatial_data)
}
```


```{r}
#| label: sentiment_neu_per_countries_map
#|

if (length(list.files(path = file.path("maps", "ch2_technology"), pattern = "sentiment_neu_per_countries")) < 4) {
    data <- readRDS(params$fn_sentiment_spatial_data)

    map <- data |>
        map_country_codes(
            map_type = "countries",
            values = "mean_neu",
            geodata_path = params$gdm_dir
        ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", mid = "white", high = "#56B4E9", midpoint = 0) +
        ggplot2::ggtitle("Mean neutral sentiment (0 - 1) - all countries")

    map_sel <- data |>
        dplyr::filter(n > params$min_count_sentiment_timeseries) |>
        map_country_codes(
            map_type = "countries",
            values = "mean_neu",
            geodata_path = params$gdm_dir
        ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", mid = "white", high = "#56B4E9", midpoint = 0) +
        ggplot2::ggtitle("Mean neutral sentiment (0 - 1) - more than 10 works")

    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_neu_per_countries_all.pdf"),
        width = 12,
        height = 8,
        map
    )
    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_neu_per_countries_all.png"),
        width = 12,
        height = 8,
        map
    )

    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_neu_per_countries_10.pdf"),
        width = 12,
        height = 8,
        map_sel
    )
    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_neu_per_countries_10.png"),
        width = 12,
        height = 8,
        map_sel
    )

    rm(map, data)
}
```


```{r}
#| label: sentiment_pos_per_countries_map
#|

if (length(list.files(path = file.path("maps", "ch2_technology"), pattern = "sentiment_pos_per_countries")) < 4) {
    data <- readRDS(params$fn_sentiment_spatial_data)

    map <- data |>
        map_country_codes(
            map_type = "countries",
            values = "mean_pos",
            geodata_path = params$gdm_dir
        ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", mid = "white", high = "#56B4E9", midpoint = 0) +
        ggplot2::ggtitle("Mean positive sentiment (0 - 1) - all countries")

    map_sel <- data |>
        dplyr::filter(n > params$min_count_sentiment_timeseries) |>
        map_country_codes(
            map_type = "countries",
            values = "mean_pos",
            geodata_path = params$gdm_dir
        ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", mid = "white", high = "#56B4E9", midpoint = 0) +
        ggplot2::ggtitle("Mean positive sentiment (0 - 1) - more than 10 works")

    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_pos_per_countries_all.pdf"),
        width = 12,
        height = 8,
        map
    )
    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_pos_per_countries_all.png"),
        width = 12,
        height = 8,
        map
    )

    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_pos_per_countries_10.pdf"),
        width = 12,
        height = 8,
        map_sel
    )
    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_pos_per_countries_10.png"),
        width = 12,
        height = 8,
        map_sel
    )

    rm(map, data)
}
```

```{r}
#| label: sentiment_neg_per_countries_map
#|
if (length(list.files(path = file.path("maps", "ch2_technology"), pattern = "sentiment_neg_per_countries")) < 4) {
    data <- readRDS(params$fn_sentiment_spatial_data)

    map <- data |>
        map_country_codes(
            map_type = "countries",
            values = "mean_neg",
            geodata_path = params$gdm_dir
        ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", mid = "white", high = "#56B4E9", midpoint = 0) +
        ggplot2::ggtitle("Mean negative sentiment (0 - 1) - all countries")

    map_sel <- data |>
        dplyr::filter(n > params$min_count_sentiment_timeseries) |>
        map_country_codes(
            map_type = "countries",
            values = "mean_pos",
            geodata_path = params$gdm_dir
        ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", mid = "white", high = "#56B4E9", midpoint = 0) +
        ggplot2::ggtitle("Mean negative sentiment (0 - 1) - more than 10 works")


    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_neg_per_countries_all.pdf"),
        width = 12,
        height = 8,
        map
    )
    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_neg_per_countries_all.png"),
        width = 12,
        height = 8,
        map
    )

    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_neg_per_countries_10.pdf"),
        width = 12,
        height = 8,
        map_sel
    )
    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_neg_per_countries_10.png"),
        width = 12,
        height = 8,
        map_sel
    )

    rm(map, data)
}
```



```{r}
#| label: sentiment_compound_per_countries_map
#|

if (length(list.files(path = file.path("maps", "ch2_technology"), pattern = "sentiment_comp_per_countries")) < 4) {
    data <- readRDS(params$fn_sentiment_spatial_data)

    map <- data |>
        map_country_codes(
            map_type = "countries",
            values = "mean_compound",
            geodata_path = params$gdm_dir
        ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", mid = "white", high = "#56B4E9", midpoint = 0) +
        ggplot2::ggtitle("Mean compound sentiment (-1: negative; 1: positive) - all countries")

    map_sel <- data |>
        dplyr::filter(n > params$min_count_sentiment_timeseries) |>
        map_country_codes(
            map_type = "countries",
            values = "mean_compound",
            geodata_path = params$gdm_dir
        ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", mid = "white", high = "#56B4E9", midpoint = 0) +
        ggplot2::ggtitle("Mean compound sentiment (-1: negative; 1: positive) - more than 10 works")

    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_comp_per_countries_all.pdf"),
        width = 12,
        height = 8,
        map
    )
    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_comp_per_countries_all.png"),
        width = 12,
        height = 8,
        map
    )

    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_comp_per_countries_10.pdf"),
        width = 12,
        height = 8,
        map_sel
    )
    ggplot2::ggsave(
        file.path("maps", "ch2_technology", "sentiment_comp_per_countries_10.png"),
        width = 12,
        height = 8,
        map_sel
    )

    rm(map, data)
}
```


### Timeseries

```{r}
#| label: sentiments_over_time_data
#|

if (!file.exists(params$fn_sentiment_temporal_data)) {
    data <- readRDS(params$fn_sentiment_results) |>
        select(
            work_id = id,
            year = date,
            neg,
            neu,
            pos,
            compound
        ) |>
        dplyr::group_by(year) |>
        dplyr::summarize(
            neg = mean(neg),
            neu = mean(neu),
            pos = mean(pos),
            compound = mean(compound),
            n = n()
        ) |>
        saveRDS(file = params$fn_sentiment_temporal_data)
}
```


```{r}
#| label: sentiments_marine_over_time_data
#|

if (!file.exists(params$fn_sentiment_marine_temporal_data)) {
    data <- readRDS(params$fn_sentiment_results) |>
        select(
            work_id = id,
            year = date,
            neg,
            neu,
            pos,
            compound
        ) |>
        dplyr::filter(
            work_id %in% oa_count$vision_technology_marine_ids
        ) |>
        dplyr::group_by(year) |>
        dplyr::summarize(
            neg = mean(neg),
            neu = mean(neu),
            pos = mean(pos),
            compound = mean(compound),
            n = n()
        ) |>
        saveRDS(file = params$fn_sentiment_marine_temporal_data)
}

```

```{r}
#| label: sentiments_over_time_all_figure
#|

if (length(list.files(path = file.path("figures", "ch2_technology"), pattern = "sentiments_over_time")) < 2) {
    figure <- readRDS(params$fn_sentiment_temporal_data) |>
        dplyr::filter(
            n > params$min_count_sentiment_timeseries
        ) |>
        tidyr::pivot_longer(cols = c(neg, neu, pos, compound), names_to = "type", values_to = "value") |>
        ggplot2::ggplot() +
        ggplot2::geom_line(aes(x = year, y = value, color = type, linetype = type)) +
        ggplot2::scale_color_manual(values = c("black", "red", "blue", "green")) +
        ggplot2::labs(
            title = paste0("Sentiment Analysis Scores (n > ", params$min_count_sentiment_timeseries, ")"),
            x = "Year",
            y = "Score",
            color = "Type",
            linetype = "Type"
        ) +
        ggplot2::theme_minimal()


    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_over_time.pdf"),
        width = 12,
        height = 6,
        figure
    )
    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_over_time.png"),
        width = 12,
        height = 6,
        figure
    )

    rm(figure)
}
```

```{r}
#| label: sentiments_over_time_table_neg_pos_figure
#|

if (length(list.files(path = file.path("figures", "ch2_technology"), pattern = "sentiments_over_time_neg_pos")) < 2) {
    figure <- readRDS(params$fn_sentiment_temporal_data) |>
        dplyr::filter(
            n > params$min_count_sentiment_timeseries
        ) |>
        tidyr::pivot_longer(cols = c(neg, pos), names_to = "type", values_to = "value") |>
        ggplot2::ggplot() +
        ggplot2::geom_line(aes(x = year, y = value, color = type, linetype = type)) +
        ggplot2::scale_color_manual(values = c("black", "red", "blue", "green")) +
        ggplot2::labs(
            title = paste0("Sentiment Analysis Scores (n > ", params$min_count_sentiment_timeseries, ")"),
            x = "Year",
            y = "Score",
            color = "Type",
            linetype = "Type"
        ) +
        ggplot2::theme_minimal()


    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_over_time_neg_pos.pdf"),
        width = 12,
        height = 6,
        figure
    )
    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_over_time_neg_pos.png"),
        width = 12,
        height = 6,
        figure
    )

    rm(figure)
}
```


```{r}
#| label: sentiments_marine_over_time_table_neg_pos_figure
#|

if (length(list.files(path = file.path("figures", "ch2_technology"), pattern = "sentiments_marine_over_time_neg_pos")) < 2) {
    figure <- readRDS(params$fn_sentiment_marine_temporal_data) |>
        dplyr::filter(
            n > params$min_count_sentiment_timeseries
        ) |>
        tidyr::pivot_longer(cols = c(neg, pos), names_to = "type", values_to = "value") |>
        ggplot2::ggplot() +
        ggplot2::geom_line(aes(x = year, y = value, color = type, linetype = type)) +
        ggplot2::scale_color_manual(values = c("black", "red", "blue", "green")) +
        ggplot2::labs(
            title = paste0("Sentiment Analysis Scores (n > ", params$min_count_sentiment_timeseries, ")"),
            x = "Year",
            y = "Score",
            color = "Type",
            linetype = "Type"
        ) +
        ggplot2::theme_minimal()


    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_marine_over_time_neg_pos.pdf"),
        width = 12,
        height = 6,
        figure
    )
    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_marine_over_time_neg_pos.png"),
        width = 12,
        height = 6,
        figure
    )

    rm(figure)
}
```

```{r}
#| label: sentiments_neg_over_time_figure
#|

if (length(list.files(path = file.path("figures", "ch2_technology"), pattern = "sentiments_neg_over_time")) < 2) {
    figure <- readRDS(params$fn_sentiment_temporal_data) |>
        dplyr::filter(
            n > params$min_count_sentiment_timeseries
        ) |>
        ggplot2::ggplot() +
        ggplot2::geom_line(ggplot2::aes(x = year, y = neg)) +
        ggplot2::labs(
            title = paste0("Sentiment Analysis negative Score (n > ", params$min_count_sentiment_timeseries, ")"),
            x = "Year",
            y = "Negative score"
        ) +
        ggplot2::theme_minimal()

    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_neg_over_time.pdf"),
        width = 12,
        height = 6,
        figure
    )
    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_neg_over_time.png"),
        width = 12,
        height = 6,
        figure
    )

    rm(figure)
}
```

```{r}
#| label: sentiments_neu_over_time_figure
#|
if (length(list.files(path = file.path("figures", "ch2_technology"), pattern = "sentiments_neu_over_time")) < 2) {
    figure <- readRDS(params$fn_sentiment_temporal_data) |>
        dplyr::filter(
            n > params$min_count_sentiment_timeseries
        ) |>
        ggplot2::ggplot() +
        ggplot2::geom_line(ggplot2::aes(x = year, y = neu)) +
        ggplot2::labs(
            title = paste0("Sentiment Analysis neutral Score (n > ", params$min_count_sentiment_timeseries, ")"),
            x = "Year",
            y = "Neutral score"
        ) +
        ggplot2::theme_minimal()

    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_neu_over_time.pdf"),
        width = 12,
        height = 6,
        figure
    )
    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_neu_over_time.png"),
        width = 12,
        height = 6,
        figure
    )

    rm(figure)
}
```


```{r}
#| label: sentiments_pos_over_time_figure
#|

if (length(list.files(path = file.path("figures", "ch2_technology"), pattern = "sentiments_pos_over_time")) < 2) {
    figure <- readRDS(params$fn_sentiment_temporal_data) |>
        dplyr::filter(
            n > params$min_count_sentiment_timeseries
        ) |>
        ggplot2::ggplot() +
        ggplot2::geom_line(ggplot2::aes(x = year, y = pos)) +
        ggplot2::labs(
            title = paste0("Sentiment Analysis positive Score (n > ", params$min_count_sentiment_timeseries, ")"),
            x = "Year",
            y = "Positive score"
        ) +
        ggplot2::theme_minimal()

    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_pos_over_time.pdf"),
        width = 12,
        height = 6,
        figure
    )
    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_pos_over_time.png"),
        width = 12,
        height = 6,
        figure
    )

    rm(figure)
}
```


```{r}
#| label: sentiments_comp_over_time_figure
#|
if (length(list.files(path = file.path("figures", "ch2_technology"), pattern = "sentiments_comp_over_time")) < 2) {
    figure <- readRDS(params$fn_sentiment_temporal_data) |>
        dplyr::filter(
            n > params$min_count_sentiment_timeseries
        ) |>
        ggplot2::ggplot() +
        ggplot2::geom_line(ggplot2::aes(x = year, y = compound)) +
        ggplot2::labs(
            title = paste0("Sentiment Analysis Compound Score (n > ", params$min_count_sentiment_timeseries, ")"),
            x = "Year",
            y = "Compound score"
        ) +
        ggplot2::theme_minimal()

    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_comp_over_time.pdf"),
        width = 12,
        height = 6,
        figure
    )
    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_comp_over_time.png"),
        width = 12,
        height = 6,
        figure
    )

    rm(figure)
}
```

```{r}
#| label: sentiments_marine_over_time_neg_pos_ridgeplot_figure
#|

if (length(list.files(path = file.path("figures", "ch2_technology"), pattern = "sentiments_marine_over_time_neg_pos_ridge")) < 2) {
    figure <- readRDS(params$fn_sentiment_results) |>
        select(
            work_id = id,
            year = date,
            neg,
            neu,
            pos,
            compound
        ) |>
        dplyr::ungroup() |>
        dplyr::filter(
            year >= 1980
        ) |>
        mutate(
            year = as.factor(year)
        ) |>
        ggplot() +
        geom_density_ridges(aes(x = pos, y = year, fill = "positive"), rel_min_height = 0.005) +
        geom_density_ridges(aes(x = -neg, y = year, fill = "negative"), rel_min_height = 0.005)

    # Calculate the number of points per year
    counts <- figure$data %>%
        group_by(year) %>%
        summarise(
            n = n()
        )

    # Add the number of points per year as text
    figure <- figure +
        geom_text(data = counts, aes(x = Inf, y = year, label = n), hjust = "inward", vjust = 0.5)



    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_marine_over_time_neg_pos_ridge.pdf"),
        width = 12,
        height = 6,
        figure
    )
    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_marine_over_time_neg_pos_ridge.png"),
        width = 12,
        height = 6,
        figure
    )

    rm(figure)
}
```


```{r}
#| label: sentiments_marine_over_time_neg_pos_figure
#|

if (length(list.files(path = file.path("figures", "ch2_technology"), pattern = "sentiments_over_time_neg_pos")) < 2) {
    figure <- readRDS(params$fn_sentiment_temporal_data) |>
        dplyr::filter(
            n > params$min_count_sentiment_timeseries
        ) |>
        tidyr::pivot_longer(cols = c(neg, pos), names_to = "type", values_to = "value") |>
        ggplot2::ggplot() +
        ggplot2::geom_line(aes(x = year, y = value, color = type, linetype = type)) +
        ggplot2::scale_color_manual(values = c("black", "red", "blue", "green")) +
        ggplot2::labs(
            title = paste0("Sentiment Analysis Scores (n > ", params$min_count_sentiment_timeseries, ")"),
            x = "Year",
            y = "Score",
            color = "Type",
            linetype = "Type"
        ) +
        ggplot2::theme_minimal()


    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_over_time_neg_pos.pdf"),
        width = 12,
        height = 6,
        figure
    )
    ggplot2::ggsave(
        file.path("figures", "ch2_technology", "sentiments_over_time_neg_pos.png"),
        width = 12,
        height = 6,
        figure
    )

    rm(figure)
}
```


## Extract `marine papers with sentiment scores

```{r}
#| label: extract_marine_papers
#|

if (!file.exists(params$fn_marine_sentiment_all)) {
    corpus_read(params$corpus_dir) |>
        dplyr::filter(
            id %in% oa_count$vision_technology_marine_ids
        ) |>
        dplyr::select(id, doi, author_abbr, display_name, ab) |>
        dplyr::rename(abstract = ab, title = display_name) |>
        dplyr::collect() |>
        dplyr::slice_sample(n = 250) |>
        dplyr::mutate(
            abstract = substr(abstract, start = 1, stop = 5000)
        ) |>
        dplyr::left_join(
            y = readRDS(params$fn_sentiment_results) |>
                dplyr::select(
                    id,
                    neg,
                    neu,
                    pos,
                    compound
                ),
            by = "id"
        ) |>
        writexl::write_xlsx(path = params$fn_marine_sentiment_all)
}

if (!file.exists(params$fn_marine_sentiment)) {
    corpus_read(params$corpus_dir) |>
        dplyr::filter(
            id %in% oa_count$vision_technology_marine_ids
        ) |>
        dplyr::select(id, doi, author_abbr, display_name, ab) |>
        dplyr::rename(abstract = ab, title = display_name) |>
        dplyr::collect() |>
        dplyr::slice_sample(n = 250) |>
        dplyr::mutate(
            abstract = substr(abstract, start = 1, stop = 5000)
        ) |>
        dplyr::left_join(
            y = readRDS(params$fn_sentiment_results) |>
                dplyr::select(
                    id,
                    neg,
                    neu,
                    pos,
                    compound
                ),
            by = "id"
        ) |>
        writexl::write_xlsx(path = params$fn_marine_sentiment)
}

```


# Results

The results are based on data downloaded or accessed at:

```{r}
#| label: corpus_time
#| 

c_time <- list.files(
    path = params$pages_dir,
    recursive = TRUE, 
    pattern = ".rds$", 
    full.names = TRUE
) |>
    file.mtime() |>
    as.Date() |>
    unique()
```

- **Technology Corpus**:  located at ``r params$corpus_dir`` downloaded at **`r c_time`** from [OpenAlex](https://openalex.org)
- **Counts**: obtained from at **`r oa_count$timestamp |> as.Date()`** from [OpenAlex](https://openalex.org)


## `vision AND technology` in TCA Corpus

For the TCA Corpus, we do have 
**`r read_corpus(params$corpus_dir) |> nrow() |> formatC(format = "f", big.mark = ",", digits = 0)`** number of works.


## Random Sample of 250 works
An Excel file conataining a random sample of 250 works from the Technology Corpus (`technology` AND `vision` AND `nature` AND `transformativechange`) with the fields `id`, `doi`, `author_abbr` and `abstract` of the papers. The Excel file can be downloaded from  [here](params$fn_random_sample_250){target=_blank}. 

## Subfields

The subfields are based on the main topic assigned to each work. There are other topics also assigned, but this one has been identified as the main topic by an algorythm. `count` is the number of works in the `vision AND technology` corpus which have been assigned to the subfield.

**Please take a look at these subfields of the topics to identify the ones to be filtered out.**

The easies would be to download the Excel file through the button and to mark the subfields to be filtered out.
```{r}
IPBES.R::table_dt((oa_count$vision_technology_subfields |> dplyr::arrange(desc(count))), fixedColumns = NULL, fn = "Vision Technology Subfields")
```

## Publications over time

![Publications over time of different corpora](figures/ch2_technology/publications_over_time.png)

A pdf of the graph can be downloaded [here](figures/ch2_technology/publications_over_time.pdf){target=_blank}.



## Sentiment Analysis

Two `.parquet` files containing the `id`, `publication_year` and `ab` (abstract) were extracted and are available upon request due to their size.

For analyzing the sentiments of the provided abstracts, we have used the Python NLTK package, and VADER (Valence Aware Dictionary for Sentiment Reasoning) which is an NLTK module that provides sentiment scores based on the words used. VADER is a pre-trained, rule-based sentiment analysis model in which the terms are generally labeled as per their semantic orientation as either positive or negative.

The main advantage/reason for using this model was that it doesn't require a labbed training dataset.
The output of the model is 4 statistical scores: 

- **compound**: composite score that summarizes the overall sentiment of the text, where scores close to 1 indicate a positive sentiment, scores close to -1 indicate a negative sentiment, and scores close to 0 indicate a neutral sentiment
- **negative**: percentage of negative sentiments in the text 
- **neutral**: percentage of neutral sentiments in the text
- **positive**: percentage of positive sentiments in the text

```{r}
#| label: sentiment_analysis_table
#|

readRDS(params$fn_sentiment_results) |>
    IPBES.R::table_dt(fn = "sentiment_scores", fixedColumns = list(leftColumns = 2))
```

Here is the per country table

```{r}
#| label: sentiments_countries_table
#|

readRDS(params$fn_sentiment_spatial_data) |>
    IPBES.R::table_dt(fn = "sentiments_comp_over_time")
rm(data)
```

### Sentiments Over Time

This graphs shows the sentiment scores of the sentiment analysis over time.


![](`r file.path("figures", "ch2_technology", "sentiments_over_time.png")`)

To download high resolution, [click here](`r file.path("figures", "ch2_technology", "sentiments_over_time.pdf")`){target="_blank"}


For clarity, here only the positive and egative sentiments.

![](`r file.path("figures", "ch2_technology", "sentiments_over_time_neg_pos.png")`)

To download high resolution, [click here](`r file.path("figures", "ch2_technology", "sentiments_over_time_neg_pos.pdf")`){target="_blank"}


### Negative Sentiment

#### Over Time

This graphs shows the **negative score** of the sentiment analysis over time. It only 


![](`r file.path("figures", "ch2_technology", "sentiments_neg_over_time.png")`)

To download high resolution, [click here](`r file.path("figures", "ch2_technology", "sentiments_neg_over_time.pdf")`){target="_blank"}


#### Per country

![](`r file.path("maps", "ch2_technology", "sentiment_neg_per_countries_all.png")`)

To download high resolution, [click here](`r file.path("maps", "ch2_technology", "sentiment_neg_per_countries_all.pdf")`){target="_blank"}

![](`r file.path("maps", "ch2_technology", "sentiment_neg_per_countries_10.png")`)

To download high resolution, [click here](`r file.path("maps", "ch2_technology", "sentiment_neg_per_countries_10.pdf")`){target="_blank"}


### Neutral Sentiment

#### Over Time

This graphs shows the **compound score** of the sentiment analysis over time. It only 



![](`r file.path("figures", "ch2_technology", "sentiments_neu_over_time.png")`)

To download high resolution, [click here](`r file.path("figures", "ch2_technology", "sentiments_neu_over_time.pdf")`){target="_blank"}


#### Per country


![](`r file.path("maps", "ch2_technology", "sentiment_neu_per_countries_all.png")`)

To download high resolution, [click here](`r file.path("maps", "ch2_technology", "sentiment_neu_per_countries_all.pdf")`){target="_blank"}

![](`r file.path("maps", "ch2_technology", "sentiment_neu_per_countries_10.png")`)

To download high resolution, [click here](`r file.path("maps", "ch2_technology", "sentiment_neu_per_countries_10.pdf")`){target="_blank"}




### Positive Sentiment

#### Over Time

This graphs shows the **compound score** of the sentiment analysis over time. It only 

![](`r file.path("figures", "ch2_technology", "sentiments_pos_over_time.png")`)

To download high resolution, [click here](`r file.path("figures", "ch2_technology", "sentiments_pos_over_time.pdf")`){target="_blank"}

#### Per country

![](`r file.path("maps", "ch2_technology", "sentiment_pos_per_countries_all.png")`)

To download high resolution, [click here](`r file.path("maps", "ch2_technology", "sentiment_pos_per_countries_all.pdf")`){target="_blank"}

![](`r file.path("maps", "ch2_technology", "sentiment_pos_per_countries_10.png")`)

To download high resolution, [click here](`r file.path("maps", "ch2_technology", "sentiment_neu_per_countries_10.pdf")`){target="_blank"}




### Compound Sentiment

#### Over Time

This graphs shows the **compound score** of the sentiment analysis over time. It only 

![](`r file.path("figures", "ch2_technology", "sentiments_comp_over_time.png")`)

To download high resolution, [click here](`r file.path("figures", "ch2_technology", "sentiments_comp_over_time.pdf")`){target="_blank"}

#### Per country


![](`r file.path("maps", "ch2_technology", "sentiment_comp_per_countries_all.png")`)

To download high resolution, [click here](`r file.path("maps", "ch2_technology", "sentiment_comp_per_countries_all.pdf")`){target="_blank"}

![](`r file.path("maps", "ch2_technology", "sentiment_comp_per_countries_10.png")`)

To download high resolution, [click here](`r file.path("maps", "ch2_technology", "sentiment_comp_per_countries_10.pdf")`){target="_blank"}

### Marine Vision and Technology Sentiments

This graphs shows the **positive and negative score** of the sentiment analysis over time.

![](`r file.path("figures", "ch2_technology", "sentiments_marine_over_time_neg_pos.png")`)

To download high resolution, [click here](`r file.path("figures", "ch2_technology", "sentiments_marine_over_time_neg_pos.pdf")`){target="_blank"}

![](`r file.path("figures", "ch2_technology", "sentiments_mean_over_time_neg_poss_ridge.png")`)

To download high resolution, [click here](`r file.path("figures", "ch2_technology", "sentiments_marine_over_time_neg_pos_ridge.pdf")`){target="_blank"}
