---
title: 'Report Assessment Ch1 Evidence Causes'
subtitle: 'Data Management Report'
author:
  - name: 
        family: Krug
        given: Rainer M.    
        id: rmk
    orcid: 0000-0002-7490-0066
    email: Rainer.Krug@Senckenberg.de, Rainer@Krugs.de
    affiliation: 
      - name: Senckenberg
        city: Frankfurt (Main)
        url: https://www.senckenberg.de/en/institutes/sbik-f/
    roles: [author, editor]
abstract: > 
  A short description what this is about.
  This is not a tracditional abstract, but rather something else ...
# keywords:
#   - aaaaa
#   - bbbbb
license: "CC BY"
copyright: 
  holder: No idea
  year: 2024
citation: 
  type: report
  container-title: IPBES Data Management Report
  doi: XXXXXX
doi: XXXXXX
version: 0.0.1

format:
    html:
        toc: true
        toc-depth: 4
        toc_expand: true
        embed-resources: true
        code-fold: true
        code-summary: 'Show the code'
        grid:
            sidebar-width: 0px
            body-width: 4000px
            margin-width: 200px
            gutter-width: 1.5rem      
---


[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10251349.svg)](https://doi.org/10.5281/zenodo.10251349)
[![GitHub release](https://img.shields.io/github/release/IPBES-Data/IPBES_TCA_Corpus.svg)](https://github.com/IPBES-Data/IPBES_TCA_Corpus/releases/latest)
[![GitHub commits since latest release](https://img.shields.io/github/commits-since/IPBES-Data/IPBES_TCA_Corpus/latest)](https://github.com/IPBES-Data/IPBES_TCA_Corpus/commits/main)
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)

```{r}
#| label: setup
#| include: false

if (!exists("params")) {
    params <- rmarkdown::yaml_front_matter("IPBES_Ch1_evidence_causes.qmd")$params
}

build <- as.integer(readLines("buildNo_ch1_evidence_causes"))
build <- build + 1
writeLines(as.character(build), "buildNo_ch1_evidence_causes")

knitr::opts_chunk$set(message = NA)

library(openalexR)
library(arrow)
library(dplyr)
library(IPBES.R)
library(tictoc)

ethical_st <- readLines(file.path("inputs", "ch1_evidence_causes", "ethical.txt")) |>
    paste(collapse = " ")

concepts_1_st <- readLines(file.path("inputs", "ch1_evidence_causes", "concepts_1.txt")) |>
    paste(collapse = " ")

concepts_2_st <- readLines(file.path("inputs", "ch1_evidence_causes", "concepts_2.txt")) |>
    paste(collapse = " ")

narrowed_tca_st <- readLines(file.path("inputs", "ch1_evidence_causes", "narrowed_tca.txt")) |>
    paste(collapse = " ")

criteria_1_st <- readLines(file.path("inputs", "ch1_evidence_causes", "criteria_1.txt")) |>
    paste(collapse = " ")

criteria_2_st <- readLines(file.path("inputs", "ch1_evidence_causes", "criteria_2.txt")) |>
    paste(collapse = " ")

criteria_3_st <- readLines(file.path("inputs", "ch1_evidence_causes", "criteria_3.txt")) |>
    paste(collapse = " ")

criteria_4_st <- readLines(file.path("inputs", "ch1_evidence_causes", "criteria_4.txt")) |>
    paste(collapse = " ")

biodiv_loss_1_st <- readLines(file.path("inputs", "ch1_evidence_causes", "biodiv_loss_1.txt")) |>
    paste(collapse = " ")

biodiv_loss_2_st <- readLines(file.path("inputs", "ch1_evidence_causes", "biodiv_loss_2.txt")) |>
    paste(collapse = " ")

biodiv_loss_3_1_st <- readLines(file.path("inputs", "ch1_evidence_causes", "biodiv_loss_3_1.txt")) |>
    paste(collapse = " ")

biodiv_loss_3_2_st <- readLines(file.path("inputs", "ch1_evidence_causes", "biodiv_loss_3_2.txt")) |>
    paste(collapse = " ")

biodiv_loss_3_3_st <- readLines(file.path("inputs", "ch1_evidence_causes", "biodiv_loss_3_3.txt")) |>
    paste(collapse = " ")

biodiv_loss_3_4_st <- readLines(file.path("inputs", "ch1_evidence_causes", "biodiv_loss_3_4.txt")) |>
    paste(collapse = " ")

biodiv_loss_3_5_st <- readLines(file.path("inputs", "ch1_evidence_causes", "biodiv_loss_3_5.txt")) |>
    paste(collapse = " ")

##########

nature_st <- readLines(file.path("inputs", "tca_corpus", "search terms", "nature.txt")) |>
    paste(collapse = " ")

tfc_st <- readLines(file.path("inputs", "tca_corpus", "search terms", "tfc.txt")) |>
    paste(collapse = " ")

tca_corpus_st <- paste("(", nature_st, ") AND (", tfc_st, ")")

# source(file.path("R", "ch1_evidence_causes", "functions.R"))
```

## Working Title
IPBES_TCA_Ch1_evidence_causes

## Code repo

- [Github repository](https://github.com/IPBES-Data/IPBES_TCA_Corpus)
- [Google Doc with search terms and questions](https://docs.google.com/document/d/1OHK7TKwN11XazDNLJbADmmhYRXdlMKVJBtqTRpX3S-A/edit)

## Build No: `r build`

The BuidNo is automatically increased by one each time the report is rendered. It is used to indicate different renderings when the version stays the same.

## Introduction

All searches are done on all works in OpenAlex. The search in the TCA Corpus is not possibly at the moment, but we are working on it.


### The following steps will be done in documented in this report:

See [Google Doc with search terms and questions](https://docs.google.com/document/d/1OHK7TKwN11XazDNLJbADmmhYRXdlMKVJBtqTRpX3S-A/edit) for details.

## Methods

```{r}
#| label: get_corpus_counts
#|

count <- list()

count$nature_corpus <- openalexR::oa_fetch(
    title_and_abstract.search = nature_st,
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count

count$tca_corpus <- openalexR::oa_fetch(
    title_and_abstract.search = compact(tca_corpus_st),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count

```

### 1. Ethical arguments for transformative change

The search terms is [ethical](./inputs/ch1_evidence_causes/ethical.txt){target=_blank}
on **OpenAlex**.

```{r}
#| label: get_vision_count
#|

count$ethical <- openalexR::oa_fetch(
    title_and_abstract.search = ethical_st,
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
```

The search terms is [ethical](inputs/ch1_evidence_causes/ethical.txt){target=_blank}
on **TCA Corpus**.

```{r}
#| label: get_ethical_tca_count
#|

count$ethical_tca <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", ethical_st, ") AND (", tca_corpus_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
```


### 2. Assessing broader biodiversity concepts

The search terms is [concepts_1](inputs/ch1_evidence_causes/concepts_1.txt){target=_blank}
Open Alex search.

The [concepts_1](inputs/ch1_evidence_causes/concepts_1.txt){target=_blank} search returns a subset of the [nature corpus](inputs/tca_corpus/search terms/nature.txt){target=_blank} as `biodiversity` is a subset of the nature corpus. Therefore, it is not nbecessary to subset the nature corpus and the search can be done on the complete OpenAlex corpus
.
```{r}
#| label: get_concepts_1_count
#|

count$concepts_1 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(concepts_1_st),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
```

Assessing the broader biodiversity concepts by searching for [concepts_1 corpus](inputs/ch1_evidence_causes/concepts_1.txt){target=_blank} AND [concepts_2 corpus](inputs/ch2_evidence_causes/concepts_2.txt){target=_blank}

```{r}
#| label: get_concepts_1_2_nature_count
#|

count$concepts_1_2 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", concepts_1_st, ") AND (", concepts_2_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
```



### 3. Assessing disciplinary bias in the nature corpus

To be discussed

### 4. Narrowed transformative change corpus

Here the term [narrowed_tca](inputs/ch1_evidence_causes/narrowed_tca.txt){target=_blank} is used to narrow down the TCA corpus.

```{r}
#| label: get_narrowed_tca_count
#|

count$narrowed_tca <- openalexR::oa_fetch(
    title_and_abstract.search = compact(narrowed_tca_st),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count

count$narrowed_tca_tca <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", narrowed_tca_st, ") AND (", tca_corpus_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count

count$narrowed_tca_nature <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", narrowed_tca_st, ") AND (", nature_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
```

### 5. Assessing criteria in the narrowed TFC corpus

Here the terms about criteria are used:
- [criteria_1](inputs/ch1_evidence_causes/criteria_1.txt){target=_blank}
- [criteria_2](inputs/ch1_evidence_causes/criteria_2.txt){target=_blank}
- [criteria_3](inputs/ch1_evidence_causes/criteria_3.txt){target=_blank}
- [criteria_4](inputs/ch1_evidence_causes/criteria_4.txt){target=_blank}

```{r}
#| label: get_narrowed_tca_criteria_criteria_count
#|

count$narrowed_tca_c1 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", narrowed_tca_st, ") AND (", criteria_1_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
count$narrowed_tca_c2 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", narrowed_tca_st, ") AND (", criteria_2_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
count$narrowed_tca_c3 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", narrowed_tca_st, ")  AND (", criteria_3_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
count$narrowed_tca_c4 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", narrowed_tca_st, ") AND (", criteria_4_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count

```

### 6. Assessing the literature that discusses the causes of biodiversity loss 

(using the full Nature corpus, the narrowed TFC corpus and the overlap between the full nature corpus and the narrowed TFC corpus) â€“ for thematic analysis

Here the terms about criteria are used:

- [biodiv_loss_3_1](inputs/ch1_evidence_causes/biodiv_loss_3_1.txt){target=_blank}
- [biodiv_loss_3_2](inputs/ch1_evidence_causes/biodiv_loss_3_2.txt){target=_blank}
- [biodiv_loss_3_3](inputs/ch1_evidence_causes/biodiv_loss_3_3.txt){target=_blank}
- [biodiv_loss_3_4](inputs/ch1_evidence_causes/biodiv_loss_3_4.txt){target=_blank}
- [biodiv_loss_3_5](inputs/ch1_evidence_causes/biodiv_loss_3_5.txt){target=_blank}

These need to be `AND` with
- Nature Corpus
- Narrowed TFC Corpus
- Nature Corpus `AND` Narrowed TFC Corpus

```{r}
#| label: get_narrowed_tca_criteria_count
#|

st_1_nat <- compact(paste0("(", nature_st, ") AND (", biodiv_loss_1_st, ") AND (", biodiv_loss_2_st, ")"))
st_2_tca <- compact(paste0("(", narrowed_tca_st, ") AND (", biodiv_loss_1_st, ") AND (", biodiv_loss_2_st, ")"))
st_3_nat <- compact(paste0("(", nature_st, ") AND (", narrowed_tca_st, ") AND (", biodiv_loss_1_st, ") AND (", biodiv_loss_2_st, ")"))

count$st_1_nat <- openalexR::oa_fetch(
    title_and_abstract.search = st_1_nat,
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count

count$st_2_tca <- openalexR::oa_fetch(
    title_and_abstract.search = st_2_tca,
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count

count$st_3_nat <- openalexR::oa_fetch(
    title_and_abstract.search = st_3_nat,
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count

count$biodiv_loss_nat_s_1 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", st_1_nat, ") AND (", biodiv_loss_3_1_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
count$biodiv_loss_nat_s_2 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", st_1_nat, ") AND (", biodiv_loss_3_2_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
count$biodiv_loss_nat_s_3 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", st_1_nat, ") AND (", biodiv_loss_3_3_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
count$biodiv_loss_nat_s_14 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", st_1_nat, ") AND (", biodiv_loss_3_4_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
count$biodiv_loss_nat_s_5 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", st_1_nat, ") AND (", biodiv_loss_3_5_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count



count$biodiv_loss_narrowed_s_1 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", st_2_tca, ") AND (", biodiv_loss_3_1_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
count$biodiv_loss_narrowed_s_2 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", st_2_tca, ") AND (", biodiv_loss_3_2_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
count$biodiv_loss_narrowed_s_3 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", st_2_tca, ") AND (", biodiv_loss_3_3_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
count$biodiv_loss_narrowed_s_14 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", st_2_tca, ") AND (", biodiv_loss_3_4_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
count$biodiv_loss_narrowed_s_5 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", st_2_tca, ") AND (", biodiv_loss_3_5_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count


count$biodiv_loss_nat_narrowed_s_1 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", st_3_nat, ") AND (", biodiv_loss_3_1_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
count$biodiv_loss_nat_narrowed_s_2 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", st_3_nat, ") AND (", biodiv_loss_3_2_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
count$biodiv_loss_nat_narrowed_s_3 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", st_3_nat, ") AND (", biodiv_loss_3_3_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
count$biodiv_loss_nat_narrowed_s_14 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", st_3_nat, ") AND (", biodiv_loss_3_4_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count
count$biodiv_loss_nat_narrowed_s_5 <- openalexR::oa_fetch(
    title_and_abstract.search = compact(paste0("(", st_3_nat, ") AND (", biodiv_loss_3_5_st, ")")),
    count_only = TRUE,
    output = "list",
    verbose = TRUE
)$count

```

```{r}
fn <- file.path("data", "ch1_evidence_causes", "counts.rds")
if (!file.exists(fn)) {
    saveRDS(count, fn)
} else {
    count <- readRDS(fn)
}
```

## TODO Download ` Corpi

The corpi download will be stored in `ch1_evidence_causes/pages` and the arrow database in `data/ch1_evidence_causes/corpus`.

This is not on github!

The corpus can be read by running `get_corpus()` which o[pens the database so that then it can be fed into a `dplyr` pipeline. After most `dplyr` functions, the actual data needs to be collected via `collect()`.

Only then is the actual data read!

Needs to be enabled by setting `eval: true` in the code block below.

### TODO Download Corpus

```{r}
#| label: get_tca_corpus
#| eval: false
#|

tic()
pages_dir <- file.path(".", "data", "ch1_evidence_causes", "pages")

dir.create(
    path = pages_dir,
    showWarnings = FALSE,
    recursive = TRUE
)

years <- oa_fetch(
    title_and_abstract.search = compact(paste0("(", vision_st, ") AND (", technology_st, ")")),
    group_by = "publication_year",
    paging = "cursor",
    verbose = FALSE
)$key

#######
#######
processed <- list.dirs(
    path = pages_dir,
    full.names = FALSE,
    recursive = FALSE
) |>
    gsub(
        pattern = paste0("^pages_publication_year=", ""),
        replacement = ""
    )

interrupted <- list.files(
    path = pages_dir,
    pattern = "^next_page.rds",
    full.names = TRUE,
    recursive = TRUE
) |>
    gsub(
        pattern = paste0("^", pages_dir, "/pages_publication_year=", ""),
        replacement = ""
    ) |>
    gsub(
        pattern = "/next_page.rds$",
        replacement = ""
    )

completed <- processed[!(processed %in% interrupted)]

years <- years[!(years %in% completed)]
#######
#######

pbmcapply::pbmclapply(
    sample(years),
    function(y) {
        message("\nGetting data for year ", y, " ...")
        output_path <- file.path(pages_dir, paste0("pages_publication_year=", y))

        dir.create(
            path = output_path,
            showWarnings = FALSE,
            recursive = TRUE
        )

        data <- oa_query(
            title_and_abstract.search = compact(paste0("(", vision_st, ") AND (", technology_st, ")")),
            publication_year = y,
            options = list(
                select = c("id", "doi", "authorships", "publication_year", "display_name", "abstract_inverted_index", "topics")
            ),
            verbose = FALSE
        ) |>
            IPBES.R::oa_request_IPBES(
                count_only = FALSE,
                output_path = output_path,
                verbose = TRUE
            )
    },
    mc.cores = 1,
    mc.preschedule = FALSE
)

toc()
```

### TODO Convert Corpus to Arrow

The fields `author` and `topics` are serialized in the arrow database and need to be unserialized by using `unserialize_arrow()` on a dataset containing the two columns.

```{r}
#| label: convert_tca_corpus_arrow
#| eval: false
tic()

pages_dir <- file.path(".", "data", "ch1_evidence_causes", "pages")
arrow_dir <- file.path(".", "data", "ch1_evidence_causes", "corpus")

years <- list.dirs(
    path = pages_dir,
    full.names = TRUE,
    recursive = FALSE
)

years_done <- list.dirs(
    path = arrow_dir,
    full.names = TRUE,
    recursive = FALSE
)

years <- years[
    !(
        gsub(
            x = years,
            pattern = paste0("^", pages_dir, "/pages_publication_year="),
            replacement = ""
        ) %in% gsub(
            x = years_done,
            pattern = paste0("^", arrow_dir, "/publication_year="),
            replacement = ""
        )
    )
]

pbapply::pblapply(
    years,
    function(year) {
        message("\n     Processing year ", year, " ...\n")
        pages <- list.files(
            path = year,
            pattern = "^page_",
            full.names = TRUE,
            recursive = TRUE
        )
        invisible(
            pbmcapply::pbmclapply(
                pages,
                function(page) {
                    data <- readRDS(file.path(page))$results |>
                        openalexR::works2df(verbose = FALSE)
                    data$author_abbr <- IPBES.R::abbreviate_authors(data)
                    data <- serialize_arrow(data)

                    data$page <- page |>
                        basename() |>
                        gsub(pattern = "^page_", replacement = "") |>
                        gsub(pattern = ".rds$", replacement = "")

                    arrow::write_dataset(
                        data,
                        path = arrow_dir,
                        partitioning = c("publication_year", "page"),
                        format = "parquet",
                        existing_data_behavior = "overwrite"
                    )
                },
                mc.cores = 6 # params$mc.cores
            )
        )
    }
)
toc()
```

### TODO Filter Corpus with TCA Corpus
```{r}
#| label: filter_corpus_with_tca
#| eval: false
#|

ids_technology <- read_corpus(file.path("data", "ch1_evidence_causes", "corpus")) |>
    dplyr::select(id) |>
    collect() |>
    unlist()

ids_tca <- read_corpus(file.path("..", "IPBES_TCA_Corpus", "data", "tca_corpus", "ch1_evidence_causes", "corpus")) |>
    dplyr::select(id) |>
    collect() |>
    unlist()

ids_subs_tca <- ids_technology[ids_technology %in% ids_tca]

arrow_tca_dir <- file.path(".", "data", "ch1_evidence_causes", "corpus_tca")
arrow_dir <- file.path(".", "data", "ch1_evidence_causes", "corpus")


year_dirs <- list.dirs(
    path = arrow_dir,
    full.names = TRUE,
    recursive = FALSE
)

year_done <- list.dirs(
    path = arrow_tca_dir,
    full.names = TRUE,
    recursive = FALSE
)

year_dirs <- year_dirs[!(basename(year_dirs) %in% basename(year_done))]

years <- basename(year_dirs) |>
    gsub(
        pattern = "publication_year=",
        replacement = ""
    )
ys <- seq_len(length(year_dirs))


pbapply::pblapply(
    ys,
    function(y) {
        data <- read_corpus(year_dirs[[y]]) |>
            dplyr::collect() |>
            dplyr::filter(id %in% ids_subs_tca)
        if (nrow(data) > 0) {
            data |>
                dplyr::mutate(publication_year = as.integer(years[[y]])) |>
                arrow::write_dataset(
                    path = arrow_tca_dir,
                    partitioning = "publication_year",
                    format = "parquet",
                    existing_data_behavior = "overwrite"
                )
        }
    }
)

toc()
```

### TODO Extract 50 random papers
```{r}
#| label: extract_random_papers
#| eval: false

fn <- file.path("data", "ch1_evidence_causes", "random_50_technology_in_tca.xlsx")

if (!file.exists(fn)) {
    set.seed(14)
    read_corpus(file.path("data", "ch1_evidence_causes", "corpus_tca")) |>
        dplyr::select(id, author_abbr, display_name, ab) |>
        dplyr::rename(abstract = ab, title = display_name) |>
        dplyr::collect() |>
        dplyr::slice_sample(n = 50) |>
        dplyr::mutate(
            abstract = substr(abstract, start = 1, stop = 5000)
        ) |>
        writexl::write_xlsx(path = fn)
}
```

# Results

## 1. Ethical arguments for transformative change

**Subset of TCA Corpus**

How many, what percentage, and what papers in the full TC corpus?

The **Ethics Corpus**  consists of  **`r count$ethical_tca`** works, which is **`r round(100 * count$ethical_tca / count$tca_corpus, digits = 2)`%** of the TCA Corpus

## 2. Assessing broader biodiversity concepts

**Subset of OpenAlex Corpus**

The Concepts 1 Corpus (talking about biodiversity in relation to conservation, management, policy, or governance ) consists of **`r count$concepts_1`** works, which is **`r round(100 * count$concepts_1 / count$nature_corpus, digits = 2)`%** of the Nature Corpus. Of these, **`r count$concepts_1_2`** (**`r round(100 * count$concepts_1__2 / count$nature_corpus, digits = 2)`%** of Nature Corpus and **`r round(100 * count$concepts_2 / count$concept_1, digits = 2)`%** of the Concept 1 Corpus) works also talk about broader than non-human species and ecosystems.

## 3. Assessing disciplinary bias in the nature corpus

To be discussed

## 4. Narrowed TFC corpus

**Subset of TCA Corpus**

The Narrowed TFC Corpus consists of **`r count$narrowed_tca_tca`** works, which is **`r round(100 * count$narrowed_tca_tca / count$tca_corpus, digits = 2)`%** of the TCA Corpus.


**Subset of Nature Corpus**

The Narrowed Nature Corpus consists of **`r count$narrowed_tca_nature`** works, which is **`r round(100 * count$narrowed_tca_nature / count$nature_corpus, digits = 2)`%** of the Nature Corpus.

## 5. Assessing criteria in the Narrowed TFC corpus


### Criteria 1

**`r count$narrowed_tca_c1`** works in the narrowed TCA Corpus, which is **`r round(100 * count$narrowed_tca_c1 / count$narrowed_tca_tca, digits = 2)`% **of the Narrowed TCA Corpus.

### Criteria 2

**`r count$narrowed_tca_c2`** works in the narrowed TCA Corpus, which is **`r round(100 * count$narrowed_tca_c2 / count$narrowed_tca_tca, digits = 2)`%** of the Narrowed TCA Corpus.

### Criteria 3

**`r count$narrowed_tca_c3`** works in the narrowed TCA Corpus, which is **`r round(100 * count$narrowed_tca_c3 / count$narrowed_tca_tca, digits = 2)`% **of the Narrowed TCA Corpus.

### Criteria 4

**`r count$narrowed_tca_c4`** works in the narrowed TCA Corpus, which is **`r round(100 * count$narrowed_tca_c4 / count$narrowed_tca_tca, digits = 2)`%** of the Narrowed TCA Corpus.

## 6. Assessing the literature that discusses the causes of biodiversity loss 

### Nature Corpus AND `Step 1` AND `Step 2`

- **`r count$st_1_nat `** works in the Nature Corpus crossed with Step 1 and Step 2 terms, which is **`r round(100 * count$st_1_nat / count$nature_corpus, digits = 2)`%** of the Nature Corpus

There are the following numbers of wotks in the Nature Corpus:

- **`r count$biodiv_loss_nat_s_1 `** works in the Nature Corpus that discuss the `Topic 1`, which is **`r round(100 * count$biodiv_loss_nat_s_1 / count$nature_corpus, digits = 2)`%**
- **`r count$biodiv_loss_nat_s_2 `** works in the Nature Corpus that discuss the `Topic 2`, which is **`r round(100 * count$biodiv_loss_nat_s_2 / count$nature_corpus, digits = 2)`%**
- **`r count$biodiv_loss_nat_s_3 `** works in the Nature Corpus that discuss the `Topic 3`, which is **`r round(100 * count$biodiv_loss_nat_s_3 / count$nature_corpus, digits = 2)`%**
- **`r count$biodiv_loss_nat_s_4 `** works in the Nature Corpus that discuss the `Topic 4`, which is **`r round(100 * count$biodiv_loss_nat_s_4 / count$nature_corpus, digits = 2)`%**
- **`r count$biodiv_loss_nat_s_5 `** works in the Nature Corpus that discuss the `Topic 5`, which is **`r round(100 * count$biodiv_loss_nat_s_5 / count$nature_corpus, digits = 2)`%**


### Narrowed TCA Corpus AND `Step 1` AND `Step 2`

- **`r count$st_3_nat `** works in the Narrowed TCA Corpus crossed the NAture Corpus and with Step 1 and Step 2 terms, which is **`r round(100 * count$st_3_nat / count$narrowed_tca_tca, digits = 2)`%** of the Narrowed TCA Corpus

There are the following numbers of wotks in the Narrowed TCA Corpus:

- **`r count$biodiv_loss_narrowed_s_1 `** works in the Narrowed TFC Corpus that discuss the `Topic 1`, which is **`r round(100 * count$biodiv_loss_narrowed_s_1 / count$narrowed_tca_tca, digits = 2)`%**
- **`r count$biodiv_loss_narrowed_s_2 `** works in the Narrowed TFC Corpus that discuss the `Topic 2`, which is **`r round(100 * count$biodiv_loss_narrowed_s_2 / count$narrowed_tca_tca, digits = 2)`%**
- **`r count$biodiv_loss_narrowed_s_3 `** works in the Narrowed TFC Corpus that discuss the `Topic 3`, which is **`r round(100 * count$biodiv_loss_narrowed_s_3 / count$narrowed_tca_tca, digits = 2)`%**
- **`r count$biodiv_loss_narrowed_s_4 `** works in the Narrowed TFC Corpus that discuss the `Topic 4`, which is **`r round(100 * count$biodiv_loss_narrowed_s_4 / count$narrowed_tca_tca, digits = 2)`%**
- **`r count$biodiv_loss_narrowed_s_5 `** works in the Narrowed TFC Corpus that discuss the `Topic 5`, which is **`r round(100 * count$biodiv_loss_narrowed_s_5 / count$narrowed_tca_tca, digits = 2)`%**

### Nature Corpus AND Narrowed TCA Corpus AND `Step 1` AND `Step 2`

- **`r count$st_2_tca `** works in the Narrowed TCA Corpus crossed with Step 1 and Step 2 terms, which is **`r round(100 * count$st_2_tca / count$narrowed_tca_nature, digits = 2)`%** of the Narrowed TCA Corpus

There are the following numbers of wotks in the Nature Corpus AND Narrowed TCA Corpus:

- **`r count$biodiv_loss_nat_narrowed_s_1 `** works in the Nature Corpus AND Narrowed TFC Corpus that discuss the `Topic 1`, which is **`r round(100 * count$biodiv_loss_nat_narrowed_s_1 / count$narrowed_tca_nature, digits = 2)`%**
- **`r count$biodiv_loss_nat_narrowed_s_2 `** works in the Nature Corpus AND Narrowed TFC Corpus that discuss the `Topic 2`, which is **`r round(100 * count$biodiv_loss_nat_narrowed_s_2 / count$narrowed_tca_nature, digits = 2)`%**
- **`r count$biodiv_loss_nat_narrowed_s_3 `** works in the Nature Corpus AND Narrowed TFC Corpus that discuss the `Topic 3`, which is **`r round(100 * count$biodiv_loss_nat_narrowed_s_3 / count$narrowed_tca_nature, digits = 2)`%**
- **`r count$biodiv_loss_nat_narrowed_s_4 `** works in the Nature Corpus AND Narrowed TFC Corpus that discuss the `Topic 4`, which is **`r round(100 * count$biodiv_loss_nat_narrowed_s_4 / count$narrowed_tca_nature, digits = 2)`%**
- **`r count$biodiv_loss_nat_narrowed_s_5 `** works in the Nature Corpus AND Narrowed TFC Corpus that discuss the `Topic 5`, which is **`r round(100 * count$biodiv_loss_nat_narrowed_s_5 / count$narrowed_tca_nature, digits = 2)`%**

