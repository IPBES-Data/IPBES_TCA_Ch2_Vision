---
title: 'Data Management Report Transformative Change Assessment Corpus - SOD'
date: today
author:
  - name: 
        family: Krug
        given: Rainer M.    
    id: rmk
    orcid: 0000-0002-7490-0066
    email: Rainer.Krug@Senckenberg.de, Rainer@Krugs.de
    affiliation: 
      - name: Senckenberg
        city: Frankfurt (Main)
        url: https://www.senckenberg.de/en/institutes/sbik-f/
    roles: [author, editor]
abstract: > 
    The literature search for the assessment corpus was conducted using search terms provided by the experts and refined in co-operation with the Knowldge and Data task force.
    The search was conducted using [OpenAlex](https://openalex.org), scripted from [R](https://cran.r-project.org) to use  the [API](https://docs.openalex.org). Search terms for the following searches were defined:
    **Transformative Change**,
    **Nature / Environment** and 
    **additional search terms for individual chapters and sub-chapters**
    To assess the quality of the corpus, sets of key-papers were selected by the experts to verify if these are in the corpus. 
    These key-papers were selected per chapter / sub-chapter to ensure that the corpus is representative of each chapter.  
keywords:
  - DMR
  - TCA
  - Assessment Corpus
license: "CC BY"

citation: 
  type: report
  container-title: Report Transformative Change Assessment Corpus
  doi: 10.5281/zenodo.10251349
doi: 10.5281/zenodo.10251349
version: 2.0.0

format:
    html:
        toc: true
        toc-depth: 5
        toc_expand: true
        embed-resources: true
        code-fold: true
        code-summary: 'Show the code'
        grid:
            sidebar-width: 0px
            body-width: 4000px
            margin-width: 200px
            gutter-width: 1.5rem      
execute:
  message: NA
params:
    # s_level_1: (transformation OR transition* OR ((shift OR change) AND (fundamental OR deep OR radical))) AND (socio OR social OR politics OR political OR governance OR economical OR cultural OR system* OR technological OR inner OR personal)  
    
    # s_tfc_rev: "('transformative change'  OR  'deliberate transformation*'  OR  'transformative turn*'  OR  'transition*'  OR  'social-ecological change*'  OR  'deep change'  OR  'fundamental alteration'  OR  'profound change'  OR  'profound transformation'  OR  'radical transformation'  OR  'transformational change'  OR  'complete change'  OR  'complete transformation'  OR  'drastic change'  OR  'in-depth transformation'  OR  'progressive change'  OR  'radical alteration'  OR  'radical change'  OR  'revolutionary change'  OR  'significant modification'  OR  'total transformation'  OR  'transition'  OR  'pathway'  OR  'power'  OR  'agency'  OR  'scale'  OR  'leverage'  OR  'context'  OR  'process'  OR  'regime'  OR  'shift'  OR  'views'  OR  'value*'  OR  'structure*'  OR  'institution*' OR  'deliberate'  OR  'structural'  OR  'fundamental'  OR  'system*'  OR  'deep'  OR  'radical'  OR  'profound'  OR  'drastic'  OR  'widespread'  OR  'political'  OR  'economical'  OR  'structur*'  OR  'complete'  OR  'progressive'  OR  'revolutionary'  OR  'substantial'  OR  'significant') AND ('transformation'  OR  'alteration'  OR  'change'  OR  'turn'  OR  'action' OR  'transition'  OR  'shift' )"
 
    s_1_oa: ""
    s_1_transformative_change: !expr paste0(readLines(file.path("inputs", "search terms", "tfc.txt")), collapse = "\n")
    s_1_nature_environment: !expr paste0(readLines(file.path("inputs", "search terms", "nature.txt")), collapse = "\n")
    s_1_tca_corpus: !expr paste("(", paste0(readLines(file.path("inputs", "search terms", "nature.txt")), collapse = "\n"), ") \nAND \n(", paste0(readLines(file.path("inputs", "search terms", "tfc.txt")), collapse = "\n"), ")")
    s_1_ch1_01: !expr paste0(readLines(file.path("inputs", "search terms", "ch1_01.txt")), collapse = "\n")
    s_1_ch1_02: !expr paste0(readLines(file.path("inputs", "search terms", "ch1_02.txt")), collapse = "\n")
    s_1_ch1_03: !expr paste0(readLines(file.path("inputs", "search terms", "ch1_03.txt")), collapse = "\n")
    s_1_ch1_04: !expr paste0(readLines(file.path("inputs", "search terms", "ch1_04.txt")), collapse = "\n")
    s_1_ch1_05: !expr paste0(readLines(file.path("inputs", "search terms", "ch1_05.txt")), collapse = "\n")
    s_1_ch1_06: !expr paste0(readLines(file.path("inputs", "search terms", "ch1_06.txt")), collapse = "\n")
    s_1_ch2: !expr paste0(readLines(file.path("inputs", "search terms", "ch2.txt")), collapse = "\n")
    s_1_ch3_01: !expr paste0(readLines(file.path("inputs", "search terms", "ch3_01.txt")), collapse = "\n")
    s_1_ch3_02: !expr paste0(readLines(file.path("inputs", "search terms", "ch3_02.txt")), collapse = "\n")
    s_1_ch3_03: !expr paste0(readLines(file.path("inputs", "search terms", "ch3_03.txt")), collapse = "\n")
    s_1_ch3_04: !expr paste0(readLines(file.path("inputs", "search terms", "ch3_04.txt")), collapse = "\n")
    s_1_ch3_05: !expr paste0(readLines(file.path("inputs", "search terms", "ch3_05.txt")), collapse = "\n")
    s_1_ch3_06: !expr paste0(readLines(file.path("inputs", "search terms", "ch3_06.txt")), collapse = "\n")
    s_1_ch4_01: !expr paste0(readLines(file.path("inputs", "search terms", "ch4_01.txt")), collapse = "\n")     
    s_1_ch4_02: !expr paste0(readLines(file.path("inputs", "search terms", "ch4_02.txt")), collapse = "\n")
    s_1_case: !expr paste0(readLines(file.path("inputs", "search terms", "case.txt")), collapse = "\n")
    s_1_ch2_vision_case: !expr paste("(", paste0(readLines(file.path("inputs", "search terms", "ch2.txt")), collapse = "\n"), ") \nAND \n(", paste0(readLines(file.path("inputs", "search terms", "case.txt")), collapse = "\n"), ")")
   
    concept_cuttoff: 0.6

    key_papers:
#      - Ch_1:
        - "./inputs/key papers/Ch 1 - Arun.csv"
        - "./inputs/key papers/Ch 1 - pdf.csv"
        - "./inputs/key papers/Ch 1 - word.csv"
#      - Ch_2:
        - "./inputs/key papers/Ch 2 - pdf.csv"
        - "./inputs/key papers/Ch 2 - Sebastian.csv"
#      - Ch_3_Cl_1:
        - "./inputs/key papers/Ch 3 - Cl1.csv"
#      - Ch_3_Cl_3:
        - "./inputs/key papers/Ch 3 - Cl3.csv"
#      - Ch_3_Cl_4:
        - "./inputs/key papers/Ch 3 - Cl4.csv"
#      - Ch_3_Cl_5:
        - "./inputs/key papers/Ch 3 - Cl5.csv"
#      - Ch_3Cl_6:
        - "./inputs/key papers/Ch 3 - Cl6.csv"
#      - Ch_3:
        - "./inputs/key papers/Ch 3 - pdf.csv"
#      - Ch_4_Cl_1:
        - "./inputs/key papers/Ch 4 - Challenge 1.csv"
#      - Ch_4_Cl_2:
        - "./inputs/key papers/Ch 4 - Challenge 2.csv"
#      - Ch_4_Cl_3:
        - "./inputs/key papers/Ch 4 - Challenge 3.csv"
#      - Ch_4_Cl_4:
        - "./inputs/key papers/Ch 4 - Challenge 4.csv"
#      - Ch_4_Cl_5:
        - "./inputs/key papers/Ch 4 - Challenge 5.csv"
#      - Ch_5:
        - "./inputs/key papers/Ch 5 - Hannah.csv"
        - "./inputs/key papers/Ch 5 - Victoria.csv"
        - "./inputs/key papers/Ch 5 -.csv"

    sample_size: 10000
    mc.cores: 8
---




[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10251349.svg)](https://doi.org/10.5281/zenodo.10251349)
[![GitHub release](https://img.shields.io/github/release/IPBES-Data/IPBES_TCA_Corpus.svg)](https://github.com/IPBES-Data/IPBES_TCA_Corpus/releases/latest)
[![GitHub commits since latest release](https://img.shields.io/github/commits-since/IPBES-Data/IPBES_TCA_Corpus/latest)](https://github.com/IPBES-Data/IPBES_TCA_Corpus/commits/main)
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)


```{r}
#| label: setup
#| include: false
knitr::opts_chunk$set(message = NA)

build <- as.integer(readLines("buildNo"))
build <- build + 1
writeLines(as.character(build), "buildNo")

if (!exists("params")) {
    params <- rmarkdown::yaml_front_matter("./IPBES_TCA_Corpus_DMP.qmd")$params
}

knitr::opts_chunk$set(message = NA)

library(openalexR)
library(dplyr)

library(tictoc)

library(parallel)
library(pbmcapply)
library(pbapply)

library(tibble)

library(knitr)
library(DT)

# Function to make the search strings compacter
compact <- function(x) {
    x |>
        gsub(pattern = "\n", replacement = " ") |>
        gsub(pattern = "\\*", replacement = "") |>
        gsub(pattern = "\\s+", replacement = " ") |>
        gsub(pattern = "\\( ", replacement = "(") |>
        gsub(pattern = " )", replacement = ")")
}

if (!require("IPBES.R")) {
    install.packages("IPBES.R", repos = c("https://ipbes-data.r-universe.dev", "https://cloud.r-project.org"))
    if (!require("IPBES.R")) {
        stop("Package `IPBES.R` is not available and could not be installed!")
    }
}

# A single core request is needed to make multicore parallel processing work
x <- oa_request(oa_query("bidiversity"), count_only = TRUE)
rm(x)
```

# Working Title
IPBES_TCA_Corpus

## Code repo

[Github repository](https://github.com/IPBES-Data/IPBES_TCA_Corpus)

## Build No: ``r build``

# Introduction
The following terminology is used in this document:

- **Individual corpus**: The corpus resulting from one search term, e.g. `transformative` or `nature` or `ChX_Y`
- **Assessment Corpus**: The corpus resulting from the search terms `transformative AND nature`
- **Chapter corpus**: The corpus resulting from `transformative AND Nature AND ChX_Y` 

The following searches are conducted on Title and Abstrat only as the availability of fulltext drops in 2020. OpenAlex did "inherit" fro Microsoft Academic their initial corpus in 2021 which contained a lot of fulltext for searches. After that time, other sources had to be used which did not include fulltext for searches. To eliminate this bias, we linit the search for terms in abstract and title only.

## Search Terms {#sec-search_terms}
Here are the search terms used in this document. They were provided by the authors, and some adaptations were done by the tsu to adopt them for OpenAlex.

### Transformative Change {#sec-transform}



```{r}
#| label: s_1_transformative_change

cat(params$s_1_transformative_change)
```



### Nature {#sec-nature}



```{r}
#| label: s_1_nature_environment
#|

cat(params$s_1_nature_environment)
```


### Assessment Corpus {#sec-tca-corpus}

```{r}
#| label: s_1_tca_corpus
#|

cat(params$s_1_tca_corpus)
```


### Chapter 1

#### 01 {#sec-ch1-01}



```{r}
#| label: s_1_ch1_01
#|

cat(params$s_1_ch1_01)
```



#### 02 {#sec-ch1-02}



```{r}
#| label: s_1_ch1_02
#|

cat(params$s_1_ch1_02)
```



#### 03 {#sec-ch1-03}



```{r}
#| label: s_1_ch1_03
#|

cat(params$s_1_ch1_03)
```



#### 04 {#sec-ch1-04}



```{r}
#| label: s_1_ch1_04
#|

cat(params$s_1_ch1_04)
```



#### 05 {#sec-ch1-05}



```{r}
#| label: s_1_ch1_05
#|

cat(params$s_1_ch1_05)
```



#### 06 {#sec-ch1-06}



```{r}
#| label: s_1_ch1_06
#|

cat(params$s_1_ch1_06)
```



### Chapter 2 {#sec-ch2}



```{r} 
#| label: s_1_ch2
#|

cat(params$s_1_ch2)
```



### Chapter 3

#### 01 {#sec-ch3-01}



```{r}
#| label: s_1_ch3_01
#|

cat(params$s_1_ch3_01)
```



#### 02 {#sec-ch3-02}



```{r}
#| label: s_1_ch3_02
#|

cat(params$s_1_ch3_02)
```



#### 03 {#sec-ch3-03}



```{r}
#| label: s_1_ch3_03
#|

cat(params$s_1_ch3_03)
```



#### 04 {#sec-ch3-04}



```{r}
#| label: s_1_ch3_04
#|

cat(params$s_1_ch3_04)
```



#### 05 {#sec-ch3-05}

```{r}
#| label: s_1_ch3_05
#|

cat(params$s_1_ch3_05)
```


#### 06 {#sec-ch3-06}



```{r}
#| label: s_1_ch3_06
#|

cat(params$s_1_ch3_06)
```


### Chapter 4

#### 01 {#sec-ch4-01}


```{r}
#| label: s_1_ch4_01
#|

cat(params$s_1_ch4_01)
```


#### 02 {#sec-ch4-02}


```{r}
#| label: s_1_ch4_02
#|

cat(params$s_1_ch4_02)
```


### Chapter 5

#### Vision {#sec-ch5_vision}



```{r}
#| label: s_1_ch5_vision
#|

cat(params$s_1_ch5_vision)
```


#### Case {#sec-case}



```{r}
#| label: s_1_case
#|

cat(params$s_1_case)
```

#### Vision & Case {#sec-ch5_vision_case}





### Download all IDs for the search TCA Corpus
Needs to be enabled by setting `eval: true` in the code block below.

```{r}
#| label: get_tca_corpus
#| eval: false
#| 

fn <- file.path(".", "data", "tca_corpus.rds")
if (file.exists(fn)) {
    tca_corpus <- readRDS(fn)
} else {
    unlink(file.path(".", "data", "pages"), recursive = TRUE)
    dir.create(
        file.path(".", "data", "pages"),
        showWarnings = FALSE,
        recursive = TRUE
    )
    openalexR::oa_query(
        title_and_abstract.search = compact(params$s_1_tca_corpus),
        options = list(
            select = c("id", "doi", "title", "abstract_inverted_index", "topics")
        ),
        verbose = TRUE
    ) |>
    IPBES.R::oa_request_IPBES(
        verbose = TRUE,
        output_path = file.path(".", "data", "pages")
    )

    saveRDS(file = file.path(".", "data", "tca_corpus_ids.rds"))
}

```

## Topics

OpenAlex assigns topics to each work in a hirarchical manner:

![](images/topic_hirarchy.png)

Please see [here](https://help.openalex.org/how-it-works/topics) for more information and [here](https://docs.google.com/spreadsheets/d/1v-MAq64x4YjhO7RWcB-yrKV5D_2vOOsxl4u6GBKEXY8/edit#gid=983250122) for a complete list of all topics and their corresponding subfields, fields and domains.

# Get and calculate Data
In this section, the data is retrieved from OpenAlex and the calculations are done. It contains the code used.
No results are shown here, so this section can be skipped.

```{r}
#| label: get_search_term_hits
#|

fn <- file.path(".", "data", "search_term_hits.rds")
if (!file.exists(fn)) {
    s_t <- grep("s_1_", names(params), value = TRUE)
    search_term_hits <- parallel::mclapply(
        s_t,
        function(stn) {
            message("getting '", stn, "' ...")
            if (grepl("_f_", stn)) {
                search <- params[[stn]]()
            } else {
                search <- params[[stn]]
            }
            search <- compact(search)
            openalexR::oa_query(filter = list(title_and_abstract.search = search)) |>
                openalexR::oa_request(count_only = TRUE, verbose = TRUE) |>
                unlist()
        },
        mc.cores = params$mc.cores,
        mc.preschedule = FALSE
    ) |>
        do.call(what = cbind) |>
        t() |>
        as.data.frame() |>
        dplyr::mutate(page = NULL, per_page = NULL) |>
        dplyr::mutate(count = formatC(count, format = "f", big.mark = ",", digits = 0))

    rownames(search_term_hits) <- s_t |>
        gsub(pattern = "s_1_", replacement = "") |>
        gsub(pattern = "f_", replacement = "") |>
        gsub(pattern = "^ch", replacement = "Chapter ") |>
        gsub(pattern = "_", replacement = " ")




    saveRDS(search_term_hits, file = fn)
} else {
    search_term_hits <- readRDS(fn)
}
```



```{r}
#| label: get_countries_tca_corpus
#|

fn <- file.path(".", "data", "countries_tca_corpus.rds")
if (!file.exists(fn)) {
    countries_tca_corpus <- openalexR::oa_query(
        filter = list(
            title_and_abstract.search = compact(params$s_1_tca_corpus)
        ),
        group_by = "authorships.countries"
    ) |>
        openalexR::oa_request(count_only = FALSE, verbose = TRUE) |>
        sapply(FUN = unlist) |>
        t() |>
        as.data.frame() |>
        dplyr::rename(iso2c = key) |>
        mutate(count = as.numeric(count))

    saveRDS(countries_tca_corpus, file = fn)
} else {
    countries_tca_corpus <- readRDS(fn)
}
```


```{r}
#| label: get_sample_tca_corpus
#| eval: true


fn <- file.path(".", "data", paste0("sample_tca_corpus_", params$sample_size, ".rds"))
fn_df <- file.path(".", "data", paste0("sample_tca_corpus_", params$sample_size, ".rds"))
if (!file.exists(fn)) {
    message("Sampling 'transformative change' corpus (n = ", params$sample_size, ") - this can take some time ...")
    sample_tca_corpus <- openalexR::oa_query(
        filter = list(
            title_and_abstract.search = compact(
            paste0(
                "(", params$s_1_transformative_change, ") AND (", params$s_1_nature_environment, ")"
            )
            )
        ),
        options = list(
            sample = params$sample_size
        )
    ) |>
        openalexR::oa_request(count_only = FALSE, verbose = TRUE)

    sample_tca_corpus_df <- oa2df(sample_tca_corpus, entity = "works")

    saveRDS(sample_tca_corpus, file = fn)
    saveRDS(sample_tca_corpus_df, file = fn_df)
} else {
    sample_tca_corpus <- readRDS(fn)
    sample_tca_corpus_df <- readRDS(fn_df)
}
```

```{r}
#| label: prim_topic_tca_corpus
#| eval: true

fn <- file.path(".", "data", paste0("prim_topics_tca_corpus.rds"))
if (!file.exists(fn)) {
    # message("Sampling 'transformative change' corpus (n = ", params$sample_size, ") - this can take some time ...")

    prim_topics_tca_corpus <- openalexR::oa_fetch(
        title_and_abstract.search = compact(params$s_1_tca_corpus),
        group_by = "primary_topic.id",
        verbose = FALSE
    )
    names(prim_topics_tca_corpus) <- c("topic_id", "topic_name", "count")
    prim_topics_tca_corpus <- prim_topics_tca_corpus[-2]
    prim_topics_tca_corpus$topic_id <- sub("https://openalex.org/T", "", prim_topics_tca_corpus$topic_id)
    prim_topics_tca_corpus <- merge(
        read.csv(file.path("inputs", "OpenAlex_topic_mapping_table - final_topic_field_subfield_table.csv")),
        prim_topics_tca_corpus,
        by = "topic_id"
    )

    prim_topics_tca_corpus <- prim_topics_tca_corpus[order(prim_topics_tca_corpus$count, decreasing = TRUE), ]

    saveRDS(prim_topics_tca_corpus, file = fn)
} else {
    prim_topics_tca_corpus <- readRDS(fn)
}
```


```{r}
#| label: TODO_get_nature_corpus_plus
#| eval: false
#|

fn <- file.path(".", "data", paste0("nature_corpus_plus.rds"))
if (!file.exists(fn)) {
    nature_corpus_plus <- openalexR::oa_fetch(
        title_and_abstract.search = compact(params$s_1_nature_environment),
        concepts.id = paste(
            "C86803240",
            "C18903297",
            "C205649164",
            "C59822182",
            "C127313418",
            "C151730666",
            "C90856448",
            "C159390177",
            "C78458016",
            "C58640448",
            "C185933670",
            "C62649853",
            "C114793014",
            "C97137747",
            "C132651083",
            "C110872660",
            "C24518262",
            "C130217890",
            "C43827410",
            sep = "|"
        ),
        sustainable_development_goals.id = paste(
            "https://metadata.un.org/sdg/14",
            "https://metadata.un.org/sdg/15",
            "https://metadata.un.org/sdg/13",
            sep = "|"
        ),
        options = list(
            select = "id, authorships"
        ),
        verbose = TRUE,
        count_only = TRUE
    )
    save(nature_corpus_plus, file = fn)
} else {
    nature_corpus_plus <- readRDS(fn)
}
```

```{r}
#| label: TODO_get_tc_corpus_plus
#| eval: false
#|

fn <- file.path(".", "data", paste0("tc_corpus_plus.rds"))
if (!file.exists(fn)) {
    tc_corpus_plus <- openalexR::oa_fetch(
        title_and_abstract.search = compact(params$s_1_transformative_change),
        concepts.id = paste(
            "C548081761",
            "C162324750",
            "C87717796",
            "C139719470",
            "C2778348673",
            "C175605778",
            "C47737302",
            "C17744445",
            "C199539241",
            "C144133560",
            "C138885662",
            "C94625758",
            "C10138342",
            "C50522688",
            "C162853370",
            "C77805123",
            "C36289849",
            "C39549134",
            "C187736073",
            "C188147891",
            "C66204764",
            "C199033989",
            "C74363100",
            "C2776867660",
            "C134560507",
            "C106159729",
            "C4249254",
            "C47768531",
            "C190248442",
            "C95124753",
            "C6303427",
            sep = "|"
        ),
        sustainable_development_goals.id = paste(
            "https://metadata.un.org/sdg/16",
            "https://metadata.un.org/sdg/10",
            "https://metadata.un.org/sdg/5",
            "https://metadata.un.org/sdg/4",
            "https://metadata.un.org/sdg/8",
            "https://metadata.un.org/sdg/1",
            "https://metadata.un.org/sdg/3",
            "https://metadata.un.org/sdg/2",
            "https://metadata.un.org/sdg/12",
            "https://metadata.un.org/sdg/9",
            "https://metadata.un.org/sdg/17",
            "https://metadata.un.org/sdg/11",
            "https://metadata.un.org/sdg/6",
            "https://metadata.un.org/sdg/7",
            sep = "|"
        ),
        options = list(
            select = "id, authorships"
        ),
        verbose = TRUE,
        count_only = TRUE
    )
    save(tc_corpus_plus, file = fn)
} else {
    tc_corpus_plus <- readRDS(fn)
}
```


```{r}
#| label: get_key_papers
#|
fn <- file.path(".", "data", "key_papers.rds")
if (!file.exists(fn)) {
    key_papers <- lapply(
        params$key_papers,
        function(fn) {
            message("Processing '", fn, "' ...")
            sapply(
                fn,
                function(x) {
                    read.csv(x) |>
                        select(DOI)
                }
            ) |>
                unlist()
        }
    )
    names(key_papers) <- gsub("\\.csv", "", basename(params$key_papers))


    key_papers <- list(
        Ch_1 = unlist(key_papers[grepl("Ch 1 -", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_2 = unlist(key_papers[grepl("Ch 2 -", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_3_Cl_1 = unlist(key_papers[grepl("Ch 3 - Cl1", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_3_Cl_3 = unlist(key_papers[grepl("Ch 3 - Cl3", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_3_Cl_4 = unlist(key_papers[grepl("Ch 3 - Cl4", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_3_Cl_5 = unlist(key_papers[grepl("Ch 3 - Cl5", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_3_Cl_6 = unlist(key_papers[grepl("Ch 3 - Cl6", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_3 = unlist(key_papers[grepl("Ch 3 - p", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_4_Cl_1 = unlist(key_papers[grepl("Ch 4 - Challenge 1", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_4_Cl_2 = unlist(key_papers[grepl("Ch 4 - Challenge 2", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_4_Cl_3 = unlist(key_papers[grepl("Ch 4 - Challenge 3", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_4_Cl_4 = unlist(key_papers[grepl("Ch 4 - Challenge 4", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_4_Cl_5 = unlist(key_papers[grepl("Ch 4 - Challenge 5", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_5 = unlist(key_papers[grepl("Ch 5 -", names(key_papers))], recursive = FALSE) |> as.vector()
    )

    saveRDS(key_papers, file = fn)
} else {
    key_papers <- readRDS(fn)
}
```


```{r}
#| label: key_works
#|

fn_kw <- file.path(".", "data", "key_works.rds")
fn_kw_df <- file.path(".", "data", "key_works_df.rds")
if (!all(file.exists(fn_kw, fn_kw_df))) {
    key_works <- parallel::mclapply(
        key_papers,
        function(kp) {
            dois <- kp[kp != ""] |>
                unlist() |>
                tolower() |>
                unique()

            openalexR::oa_fetch(doi = dois, output = "list")
        },
        mc.cores = params$mc.cores,
        mc.preschedule = FALSE
    )

    found <- sapply(
        key_works,
        function(x) {
            length(x) > 0
        }
    )

    key_works <- key_works[found]

    print("The following key paper sets were excluded as they contained no papers in OpenAlex:\n")
    print(names(found)[!found])

    saveRDS(key_works, file = fn_kw)

    key_works_df <- lapply(
        key_works,
        oa2df,
        entity = "works"
    )

    saveRDS(key_works_df, fn_kw_df)
} else {
    key_works <- readRDS(file = fn_kw)
    key_works_df <- readRDS(fn_kw_df)
}
```




```{r}
#| label: key_works_hits
#|

fn <- file.path(".", "data", "key_works_hits.rds")
if (!file.exists(fn)) {
    kws <- key_works_df
    kws$all  <- key_works_df |>
        bind_rows()

    nms <- names(kws)
    key_works_hits <- pbapply::pblapply(
        nms,
        function(nm) {
            message("Getting key paper set for ", nm, " ...")
            dois <- kws[[nm]] |>
                select(doi) |>
                distinct() |>
                unlist() |>
                unique() |>
                tolower()

            s_t <- grep("s_1_", names(params), value = TRUE)
            kw_h <- parallel::mclapply(
                s_t,
                function(stn) {
                    message("  getting '", stn, "' ...")
                    if (grepl("_f_", stn)) {
                        search <- compact(params[[stn]]())
                    } else {
                        search <- compact(params[[stn]])
                    }
                    get_count(dois = dois, list(title_and_abstract.search = search), verbose = FALSE)
                },
                mc.cores = params$mc.cores,
                mc.preschedule = FALSE
            ) |>
                do.call(what = cbind) |>
                as.data.frame()

            names(kw_h) <- s_t

            # if (ncol(kw_h) == 1){
            #     kw_h <- t(kw_h)
            #     rownames(kw_h) <- dois
            # }

            kw_h <- rbind(
                kw_h,
                colSums(kw_h)
            )

            rownames(kw_h)[[nrow(kw_h)]] <- "Total"
            return(kw_h)  
        }
    )

    names(key_works_hits) <- nms

    for (i in nms) {
        # key_works_hits[[i]] <- cbind(
        #     key_works_hits[[i]],
        #     key_works_hits_tca_filtered[[i]]
        # )

        key_works_hits[[i]] <- cbind(
            key_works_hits[[i]],
            Total = rowSums(key_works_hits[[i]])
        ) |>
            mutate(Total = Total - 1) # |>
            # relocate(tca_corpus_SDG, .after = s_1_tca_corpus)
    }

    ###

    saveRDS(key_works_hits, file = fn)
} else {
    key_works_hits <- readRDS(file = fn)
}
```


# Results

## Number of Hits per Individual Corpus

Here we show the number of hits for the key papers in the different individual corpi. The columns represent the different search terms as defined in @sec-search_terms.

```{r}
#| label: hits_per_search_term_table

dat <- cbind(
    search_term_hits
)

rownames(dat) <- dplyr::recode(
    rownames(dat),
    "transformative change" = "Transformative Change @sec-transform",
    "nature environment" = "Nature @sec-nature",
    "tca corpus" = "Assessment Corpus @sec-tca-corpus",
    "Chapter 1 01" = "Ch1 01 @sec-ch1-01",
    "Chapter 1 02" = "Ch1 02 @sec-ch1-02",
    "Chapter 1 03" = "Ch1 03 @sec-ch1-03",
    "Chapter 1 04" = "Ch1 04 @sec-ch1-04",
    "Chapter 1 05" = "Ch1 05 @sec-ch1-05",
    "Chapter 1 06" = "Ch1 06 @sec-ch1-06",
    "Chapter 2" = "Ch2  @sec-ch2",
    "Chapter 3 01" = "Ch3 01 @sec-ch3-01",
    "Chapter 3 02" = "Ch3 02 @sec-ch3-02",
    "Chapter 3 03" = "Ch3 03 @sec-ch3-03",
    "Chapter 3 04" = "Ch3 04 @sec-ch3-04",
    "Chapter 3 05" = "Ch3 05 @sec-ch3-05",
    "Chapter 3 06" = "Ch3 06 @sec-ch3-06",
    "Chapter 4 01" = "Ch4 01 @sec-ch4-01",
    "Chapter 4 02" = "Ch4 02 @sec-ch4-02",
    "Chapter 5 vision" = "Ch5 Vision @sec-ch5_vision",
    "Chapter 5 vision case" = "Ch5 Vision Case @sec-ch5_vision_case",
    "case" = "Ch5 Case @sec-case"
)

dat |>
    knitr::kable(
        caption = "Number of hits",
    )

rm(dat)
```

### Key papers in different Individual Corpi {#key_papers_in_corpi}


```{r}
#| label: key_paper_hits_in_corpi
#|

tbl <- lapply(
    names(key_works_hits),
    function(n) {
        kwh <- key_works_hits[[n]]
        if (nrow(kwh) > 0) {
            total <- grepl("Total", rownames(kwh))
            rownames(kwh)[!total] <- paste0(n, " - <a href='https://doi.org/", rownames(kwh)[!total], "' target='_blank'>Click here</a>")
            rownames(kwh)[total] <- paste0("**", n, " - Total**")
            kwh |>
                arrange(Total) |>
                apply(
                    c(1, 2),
                    function(x) {
                        ifelse(x == 0, "<font color='red'>0</font>", paste0("<font color='green'>", x, "</font>"))
                    }
                ) |>
                as.data.frame()
        } else {
            return(NULL)
        }
    }
)
tbl <- tbl[sapply(tbl, class) != "NULL"]
tbl <- do.call(what = rbind, tbl)


detail <- rbind(
    "**overall**" = c(
        paste0(
            "**",
            search_term_hits |>
                select(count) |>
                unlist() |>
                as.vector(),
            "**"
        ),
        ""
    ),
    tbl
)

detail <- detail |>
    dplyr::rename(
        "Transformative Change @sec-transform" = s_1_transformative_change,
        "Nature @sec-nature" = s_1_nature_environment,
        "Assessment Corpus @sec-tca-corpus" = s_1_tca_corpus,
        "Ch1 01 @sec-ch1-01" = s_1_ch1_01,
        "Ch1 02 @sec-ch1-02" = s_1_ch1_02,
        "Ch1 03 @sec-ch1-03" = s_1_ch1_03,
        "Ch1 04 @sec-ch1-04" = s_1_ch1_04,
        "Ch1 05 @sec-ch1-05" = s_1_ch1_05,
        "Ch1 06 @sec-ch1-06" = s_1_ch1_06,
        "Ch2  @sec-ch2" = s_1_ch2,
        "Ch3 01 @sec-ch3-01" = s_1_ch3_01,
        "Ch3 02 @sec-ch3-02" = s_1_ch3_02,
        "Ch3 03 @sec-ch3-03" = s_1_ch3_03,
        "Ch3 04 @sec-ch3-04" = s_1_ch3_04,
        "Ch3 05 @sec-ch3-05" = s_1_ch3_05,
        "Ch3 06 @sec-ch3-06" = s_1_ch3_06,
        "Ch4 01 @sec-ch4-01" = s_1_ch4_01,
        "Ch4 02 @sec-ch4-02" = s_1_ch4_02,
        # "Ch5 Vision @sec-ch5_vision" = s_1_ch5_vision,
        "Ch5 Case @sec-case" = s_1_case,
        # "Ch5 Vision Case @sec-ch5_vision_case" = s_1_ch5_vision_case
    )
```

### Key Papers in Individual Corpi

#### Summary
Each column is a different search term, and each row consists of the key papers of a specific chapter and the author who provided the key papers. The number is the number of key papers occurring in the Individual Corpus.
```{r}
in_summary <- grepl("Total|overall", rownames(detail))
knitr::kable(
    detail[in_summary, ]
)
```



#### Detail
```{r}
knitr::kable(
    detail
)
```

## TCA Corpus properties

### Countries in TCA Corpus

```{r}
#| label: countries_tca_corpus_map
#| eval: true
#|

countries_tca_corpus |>
    mutate(
        iso3c = countrycode::countrycode(
            countries_tca_corpus$key_display_name,
            origin = "country.name",
            destination = "iso3c"
        )
    ) |>
    mutate(
        log_count = log(count)
    ) |>
    map_country_codes(
        map_type = "countries",
        values = "log_count"
    )
```

### Topics in corpus

```{r}
#| label: prim_topics_tca_corpus_plot
#|

cs <- cumsum(prim_topics_tca_corpus$count)
cs |>
    plot(
        type = "l",
        xlab = "Topic",
        ylab = "Cumulative Count",
        main = "Cumulative Topics in TCA Corpus"
    )

abline(
    h = 0.95 * cs[length(cs)],
    v = min(which(cs > 0.95 * cs[length(cs)])),
    col = "red"
)

text(
    x = 0.5 * length(cs),
    y = 0.95 * cs[length(cs)],
    pos = 3,
    labels = "95% of the corpus",
    col = "red"
)
```

```{r}
#| label: prim_topics_tca_corpus_table
#|

prim_topics_tca_corpus |>
    relocate(count, .after = "topic_id") |>
    IPBES.R::table_dt(
        fn = "topics_tca_corpus", 
    )    
```

### SubFields in Corpus

```{r}
#| label: prim_subfield_tca_corpus_plot
#|
cs <- prim_topics_tca_corpus |>
    mutate(
        topic_id = NULL,
        topic_name = NULL,
        keywords = NULL,
        summary = NULL,
        wikipedia_url = NULL
    ) |>
    group_by(
        subfield_id,
    ) |>
    summarise(
        count = sum(count)
    ) |>
    arrange(desc(count)) |>
    dplyr::select(count) |>
    unlist() |>
    cumsum()
cs |>
    plot(
        type = "l",
        xlab = "Subfield",
        ylab = "Cumulative Count",
        main = "Cumulative Subfields in TCA Corpus"
    )

abline(
    h = 0.95 * cs[length(cs)],
    v = min(which(cs > 0.95 * cs[length(cs)])),
    col = "red"
)

text(
    x = 0.5 * length(cs),
    y = 0.95 * cs[length(cs)],
    pos = 3,
    labels = "95% of the corpus",
    col = "red"
)
```

```{r}
#| label: prim_subfield_tca_corpus_table
#|

prim_topics_tca_corpus |>
    mutate(
        topic_id = NULL,
        topic_name = NULL,
        keywords = NULL,
        summary = NULL,
        wikipedia_url = NULL
    ) |>
    group_by(
        subfield_id,
        subfield_name,
        field_id,
        field_name,
        domain_id,
        domain_name
    ) |>
    summarise(
        count = sum(count)
    ) |>
    arrange(desc(count)) |>
    relocate(count, .after = "subfield_id") |>
    DT::datatable(
        extensions = c(
            "Buttons",
            "FixedColumns",
            "Scroller"
        ),
        options = list(
            dom = "Bfrtip",
            buttons = list(
                list(
                    extend = "csv",
                    filename = fn
                ),
                list(
                    extend = "excel",
                    filename = fn
                ),
                list(
                    extend = "pdf",
                    filename = fn,
                    orientation = "landscape",
                    customize = DT::JS(
                        "function(doc) {",
                        "  doc.defaultStyle.fontSize = 5;", # Change the font size
                        "}"
                    )
                ),
                "print"
            ),
            scroller = TRUE,
            scrollY = JS("window.innerHeight * 0.7 + 'px'"),
            scrollX = TRUE,
            fixedColumns = list(leftColumns = 4)
        ),
        escape = FALSE
    )
```
<!-- 

# ==== APPENDIX ====


TODO: one search term per chapter with OR
TODO: CH 5 search terms missing - check in emails

TODO: 
- Tranformative
- Nature
- Ch1 01-06 OR 
- Ch2 
- Ch3 01-06 OR
- Ch4 01-02 OR
- Ch5 MISSING (Options?)
- Case-Studies

TODO: which key papers are still missing? -->


- TODO: Histogram / table with topics identified to identify non-relevant papers
