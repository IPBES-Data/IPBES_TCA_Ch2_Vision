---
title: 'Data Management Report Transformative Change Assessment Corpus - SOD'
date: today
author:
  - name: 
        family: Krug
        given: Rainer M.    
    id: rmk
    orcid: 0000-0002-7490-0066
    email: Rainer.Krug@Senckenberg.de, Rainer@Krugs.de
    affiliation: 
      - name: Senckenberg
        city: Frankfurt (Main)
        url: https://www.senckenberg.de/en/institutes/sbik-f/
    roles: [author, editor]
abstract: > 
    The literature search for the assessment corpus was conducted using search terms provided by the experts and refined in co-operation with the Knowldge and Data task force.
    The search was conducted using [OpenAlex](https://openalex.org), scripted from [R](https://cran.r-project.org) to use  the [API](https://docs.openalex.org). Search terms for the following searches were defined:
    **Transformative Change**,
    **Nature / Environment** and 
    **additional search terms for individual chapters and sub-chapters**
    To assess the quality of the corpus, sets of key-papers were selected by the experts to verify if these are in the corpus. 
    These key-papers were selected per chapter / sub-chapter to ensure that the corpus is representative of each chapter.  
keywords:
  - DMR
  - TCA
  - Assessment Corpus
license: "CC BY"

citation: 
  type: report
  container-title: Report Transformative Change Assessment Corpus
  doi: 10.5281/zenodo.10251349
doi: 10.5281/zenodo.10251349
version: 2.0.0

format:
    html:
        toc: true
        toc-depth: 5
        toc_expand: true
        embed-resources: true
        code-fold: true
        code-summary: 'Show the code'
        grid:
            sidebar-width: 0px
            body-width: 4000px
            margin-width: 200px
            gutter-width: 1.5rem      
execute:
  message: NA
params:
    # s_level_1: (transformation OR transition* OR ((shift OR change) AND (fundamental OR deep OR radical))) AND (socio OR social OR politics OR political OR governance OR economical OR cultural OR system* OR technological OR inner OR personal)  
    
    # s_tfc_rev: "('transformative change'  OR  'deliberate transformation*'  OR  'transformative turn*'  OR  'transition*'  OR  'social-ecological change*'  OR  'deep change'  OR  'fundamental alteration'  OR  'profound change'  OR  'profound transformation'  OR  'radical transformation'  OR  'transformational change'  OR  'complete change'  OR  'complete transformation'  OR  'drastic change'  OR  'in-depth transformation'  OR  'progressive change'  OR  'radical alteration'  OR  'radical change'  OR  'revolutionary change'  OR  'significant modification'  OR  'total transformation'  OR  'transition'  OR  'pathway'  OR  'power'  OR  'agency'  OR  'scale'  OR  'leverage'  OR  'context'  OR  'process'  OR  'regime'  OR  'shift'  OR  'views'  OR  'value*'  OR  'structure*'  OR  'institution*' OR  'deliberate'  OR  'structural'  OR  'fundamental'  OR  'system*'  OR  'deep'  OR  'radical'  OR  'profound'  OR  'drastic'  OR  'widespread'  OR  'political'  OR  'economical'  OR  'structur*'  OR  'complete'  OR  'progressive'  OR  'revolutionary'  OR  'substantial'  OR  'significant') AND ('transformation'  OR  'alteration'  OR  'change'  OR  'turn'  OR  'action' OR  'transition'  OR  'shift' )"
 
    s_1_oa: ""
    s_1_transformative_change: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "tfc.txt")), collapse = "\n")
    s_1_nature_environment: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "nature.txt")), collapse = "\n")
    s_1_tca_corpus: !expr paste("(", paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "nature.txt")), collapse = "\n"), ") \nAND \n(", paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "tfc.txt")), collapse = "\n"), ")")
    s_1_ch1_01: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch1_01.txt")), collapse = "\n")
    s_1_ch1_02: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch1_02.txt")), collapse = "\n")
    s_1_ch1_03: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch1_03.txt")), collapse = "\n")
    s_1_ch1_04: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch1_04.txt")), collapse = "\n")
    s_1_ch1_05: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch1_05.txt")), collapse = "\n")
    s_1_ch1_06: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch1_06.txt")), collapse = "\n")
    s_1_ch2: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch2.txt")), collapse = "\n")
    s_1_ch3_01: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch3_01.txt")), collapse = "\n")
    s_1_ch3_02: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch3_02.txt")), collapse = "\n")
    s_1_ch3_03: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch3_03.txt")), collapse = "\n")
    s_1_ch3_04: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch3_04.txt")), collapse = "\n")
    s_1_ch3_05: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch3_05.txt")), collapse = "\n")
    s_1_ch3_06: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch3_06.txt")), collapse = "\n")
    s_1_ch4_01: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch4_01.txt")), collapse = "\n")     
    s_1_ch4_02: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch4_02.txt")), collapse = "\n")
    s_1_case: !expr paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "case.txt")), collapse = "\n")
    s_1_ch2_vision_case: !expr paste("(", paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "ch2.txt")), collapse = "\n"), ") \nAND \n(", paste0(readLines(file.path("inputs", "tca_corpus", "search terms", "case.txt")), collapse = "\n"), ")")
   
    concept_cuttoff: 0.6

    key_papers:
#      - Ch_1:
        - "./inputs/key papers/Ch 1 - Arun.csv"
        - "./inputs/key papers/Ch 1 - pdf.csv"
        - "./inputs/key papers/Ch 1 - word.csv"
#      - Ch_2:
        - "./inputs/key papers/Ch 2 - pdf.csv"
        - "./inputs/key papers/Ch 2 - Sebastian.csv"
#      - Ch_3_Cl_1:
        - "./inputs/key papers/Ch 3 - Cl1.csv"
#      - Ch_3_Cl_3:
        - "./inputs/key papers/Ch 3 - Cl3.csv"
#      - Ch_3_Cl_4:
        - "./inputs/key papers/Ch 3 - Cl4.csv"
#      - Ch_3_Cl_5:
        - "./inputs/key papers/Ch 3 - Cl5.csv"
#      - Ch_3Cl_6:
        - "./inputs/key papers/Ch 3 - Cl6.csv"
#      - Ch_3:
        - "./inputs/key papers/Ch 3 - pdf.csv"
#      - Ch_4_Cl_1:
        - "./inputs/key papers/Ch 4 - Challenge 1.csv"
#      - Ch_4_Cl_2:
        - "./inputs/key papers/Ch 4 - Challenge 2.csv"
#      - Ch_4_Cl_3:
        - "./inputs/key papers/Ch 4 - Challenge 3.csv"
#      - Ch_4_Cl_4:
        - "./inputs/key papers/Ch 4 - Challenge 4.csv"
#      - Ch_4_Cl_5:
        - "./inputs/key papers/Ch 4 - Challenge 5.csv"
#      - Ch_5:
        - "./inputs/key papers/Ch 5 - Hannah.csv"
        - "./inputs/key papers/Ch 5 - Victoria.csv"
        - "./inputs/key papers/Ch 5 -.csv"

    sample_size: 10000
    mc.cores: 8
---




[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10251349.svg)](https://doi.org/10.5281/zenodo.10251349)
[![GitHub release](https://img.shields.io/github/release/IPBES-Data/IPBES_TCA_Corpus.svg)](https://github.com/IPBES-Data/IPBES_TCA_Corpus/releases/latest)
[![GitHub commits since latest release](https://img.shields.io/github/commits-since/IPBES-Data/IPBES_TCA_Corpus/latest)](https://github.com/IPBES-Data/IPBES_TCA_Corpus/commits/main)
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)


```{r}
#| label: setup
#| include: false
knitr::opts_chunk$set(message = NA)

build <- as.integer(readLines("buildNo"))
build <- build + 1
writeLines(as.character(build), "buildNo")

if (!exists("params")) {
    params <- rmarkdown::yaml_front_matter("./IPBES_TCA_Corpus_DMP.qmd")$params
}

knitr::opts_chunk$set(message = NA)

library(openalexR)
library(dplyr)
library(ggplot2)
library(patchwork)

library(tictoc)

library(parallel)
library(pbmcapply)
library(pbapply)

library(tibble)

library(knitr)
library(DT)

library(arrow)
library(parquetize)
library(purrr)
library(base64enc)

library(pbapply)
library(pbmcapply)
library(parallel)

# Function to make the search strings compacter
compact <- function(x) {
    x |>
        gsub(pattern = "\n", replacement = " ") |>
        gsub(pattern = "\\*", replacement = "") |>
        gsub(pattern = "\\s+", replacement = " ") |>
        gsub(pattern = "\\( ", replacement = "(") |>
        gsub(pattern = " )", replacement = ")")
}

if (!require("IPBES.R")) {
    install.packages("IPBES.R", repos = c("https://ipbes-data.r-universe.dev", "https://cloud.r-project.org"))
    if (!require("IPBES.R")) {
        stop("Package `IPBES.R` is not available and could not be installed!")
    }
}

# source(file.path("R", "functions.R"))

# A single core request is needed to make multicore parallel processing work
x <- oa_request(oa_query("bidiversity"), count_only = TRUE)
rm(x)

gdm_dir <- tempfile()
dir.create(gdm_dir, showWarnings = FALSE, recursive = TRUE)

pages_dir <- file.path(".", "data", "tca_corpus", "pages")
corpus_dir <- file.path(".", "data", "tca_corpus", "corpus")

on.exit({
    unlink(gdm_dir, recursive = TRUE)
})
```

# Working Title
IPBES_TCA_Corpus

## Code repo

[Github repository](https://github.com/IPBES-Data/IPBES_TCA_Corpus)

## Build No: ``r build``

# Introduction
The following terminology is used in this document:

- **Individual corpus**: The corpus resulting from one search term, e.g. `transformative` or `nature` or `ChX_Y`
- **Assessment Corpus**: The corpus resulting from the search terms `transformative AND nature`
- **Chapter corpus**: The corpus resulting from `transformative AND Nature AND ChX_Y` 

The following searches are conducted on Title and Abstrat only as the availability of fulltext drops in 2020. OpenAlex did "inherit" fro Microsoft Academic their initial corpus in 2021 which contained a lot of fulltext for searches. After that time, other sources had to be used which did not include fulltext for searches. To eliminate this bias, we linit the search for terms in abstract and title only.

## Search Terms {#sec-search_terms}
Here are the search terms used in this document. They were provided by the authors, and some adaptations were done by the tsu to adopt them for OpenAlex.

### Transformative Change {#sec-transform}



```{r}
#| label: s_1_transformative_change

cat(params$s_1_transformative_change)
```



### Nature {#sec-nature}



```{r}
#| label: s_1_nature_environment
#|

cat(params$s_1_nature_environment)
```


### Assessment Corpus {#sec-tca-corpus}

```{r}
#| label: s_1_tca_corpus
#|

cat(params$s_1_tca_corpus)
```


### Chapter 1

#### 01 {#sec-ch1-01}



```{r}
#| label: s_1_ch1_01
#|

cat(params$s_1_ch1_01)
```



#### 02 {#sec-ch1-02}



```{r}
#| label: s_1_ch1_02
#|

cat(params$s_1_ch1_02)
```



#### 03 {#sec-ch1-03}



```{r}
#| label: s_1_ch1_03
#|

cat(params$s_1_ch1_03)
```



#### 04 {#sec-ch1-04}



```{r}
#| label: s_1_ch1_04
#|

cat(params$s_1_ch1_04)
```



#### 05 {#sec-ch1-05}



```{r}
#| label: s_1_ch1_05
#|

cat(params$s_1_ch1_05)
```



#### 06 {#sec-ch1-06}



```{r}
#| label: s_1_ch1_06
#|

cat(params$s_1_ch1_06)
```



### Chapter 2 {#sec-ch2}



```{r} 
#| label: s_1_ch2
#|

cat(params$s_1_ch2)
```



### Chapter 3

#### 01 {#sec-ch3-01}



```{r}
#| label: s_1_ch3_01
#|

cat(params$s_1_ch3_01)
```



#### 02 {#sec-ch3-02}



```{r}
#| label: s_1_ch3_02
#|

cat(params$s_1_ch3_02)
```



#### 03 {#sec-ch3-03}



```{r}
#| label: s_1_ch3_03
#|

cat(params$s_1_ch3_03)
```



#### 04 {#sec-ch3-04}



```{r}
#| label: s_1_ch3_04
#|

cat(params$s_1_ch3_04)
```



#### 05 {#sec-ch3-05}

```{r}
#| label: s_1_ch3_05
#|

cat(params$s_1_ch3_05)
```


#### 06 {#sec-ch3-06}



```{r}
#| label: s_1_ch3_06
#|

cat(params$s_1_ch3_06)
```


### Chapter 4

#### 01 {#sec-ch4-01}


```{r}
#| label: s_1_ch4_01
#|

cat(params$s_1_ch4_01)
```


#### 02 {#sec-ch4-02}


```{r}
#| label: s_1_ch4_02
#|

cat(params$s_1_ch4_02)
```


### Chapter 5

#### Vision {#sec-ch5_vision}



```{r}
#| label: s_1_ch5_vision
#|

cat(params$s_1_ch5_vision)
```


#### Case {#sec-case}



```{r}
#| label: s_1_case
#|

cat(params$s_1_case)
```

#### Vision & Case {#sec-ch5_vision_case}




## Topics

OpenAlex assigns topics to each work in a hirarchical manner:

![](images/topic_hirarchy.png)

Please see [here](https://help.openalex.org/how-it-works/topics) for more information and [here](https://docs.google.com/spreadsheets/d/1v-MAq64x4YjhO7RWcB-yrKV5D_2vOOsxl4u6GBKEXY8/edit#gid=983250122) for a complete list of all topics and their corresponding subfields, fields and domains.



# Download TCA Corpus

The corpus download will be stored in `data/pages` and the arrow database in `data/corpus`.

This is not on github!

The corpus can be read by running `get_corpus()` which o[pens the database so that then it can be fed into a `dplyr` pipeline. After most `dplyr` functions, the actual data needs to be collected via `collect()`.

Only then is the actual data read!

Needs to be enabled by setting `eval: true` in the code block below.

```{r}
#| label: get_tca_corpus
#| eval: false
#|


if (!dir.exists(fn)) {
    dir.create(
        path = pages_dir,
        showWarnings = FALSE,
        recursive = TRUE
    )

    years <- oa_fetch(
        title_and_abstract.search = compact(params$s_1_tca_corpus),
        group_by = "publication_year",
        paging = "cursor",
        verbose = FALSE
    )$key

    #######
    #######
    processed <- list.dirs(
        path = pages_dir,
        full.names = FALSE,
        recursive = FALSE
    ) |>
        gsub(
            pattern = paste0("^pages_publication_year=", ""),
            replacement = ""
        )

    interrupted <- list.files(
        path = pages_dir,
        pattern = "^next_page.rds",
        full.names = TRUE,
        recursive = TRUE
    ) |>
        gsub(
            pattern = paste0("^", pages_dir, "/pages_publication_year=", ""),
            replacement = ""
        ) |>
        gsub(
            pattern = "/next_page.rds$",
            replacement = ""
        )

    completed <- processed[!(processed %in% interrupted)]

    years <- years[!(years %in% completed)]
    #######
    #######

    pbmcapply::pbmclapply(
        sample(years),
        function(y) {
            message("Getting data for year ", y, " ...")
            output_path <- file.path(pages_dir, paste0("pages_publication_year=", y))

            dir.create(
                path = output_path,
                showWarnings = FALSE,
                recursive = TRUE
            )

            data <- oa_query(
                title_and_abstract.search = compact(params$s_1_tca_corpus),
                publication_year = y,
                options = list(
                    select = c("id", "doi", "authorships", "publication_year", "title", "abstract_inverted_index", "topics")
                ),
                verbose = FALSE
            ) |>
                IPBES.R::oa_request_IPBES(
                    count_only = FALSE,
                    output_path = output_path,
                    verbose = TRUE
                )
        },
        mc.cores = params$mc.cores,
        mc.preschedule = FALSE
    )
}
```

The fields `author` and `topics` are seerialized in the arrow database and need to be unserialized by using `unserialize_arrow()` on a dataset containing the two columns.

```{r}
#| label: convert_tca_corpus_arrow
#| eval: false


# convert_pages_2_arrow(  
#     pages_dir = pages_dir, 
#     arrow_dir = corpus_dir,
#     continue = FALSE,
#     delete_arrow_dir = TRUE,
#     mc_cores = 3,
#     verbose = TRUE
# )

years <- list.dirs(
    path = pages_dir,
    full.names = TRUE,
    recursive = FALSE
)

years_done <- list.dirs(
    path = corpus_dir,
    full.names = TRUE,
    recursive = FALSE
)

years <- years[
    !(
        gsub(
            x = years,
            pattern = paste0("^", pages_dir, "/pages_publication_year="),
            replacement = ""
        ) %in% gsub(
            x = years_done,
            pattern = paste0("^", corpus_dir, "/publication_year="),
            replacement = ""
        )
    )
]

pbapply::pblapply(
    sample(years),
    function(year) {
        message("\n     Processing year ", year, " ...\n")
        pages <- list.files(
            path = year,
            pattern = "^page_",
            full.names = TRUE,
            recursive = TRUE
        )
        data <- parallel::mclapply(
            pages,
            function(page) {
                p <- readRDS(file.path(page))$results |>
                    openalexR::works2df(verbose = FALSE)
                p$author_abbr <- IPBES.R::abbreviate_authors(p)
                return(p)
            },
            mc.cores = 3 # params$mc.cores
        ) |>
            do.call(what = rbind)

        saveRDS(
            data,
            file = file.path(paste0(year, ".rds"))
        )

                    for  (i in 1:nrow(data)) {
                        data$author[[i]]$au_orcid <- as.character(data$author[[i]]$au_orcid)
                    }

        arrow::write_dataset(
            data, 
            path = corpus_dir,
            partitioning = "publication_year" ,
            format = "parquet",
            existing_data_behavior = "overwrite"
        )
    }
)
```



# Get and calculate Data
In this section, the data is retrieved from OpenAlex and the calculations are done. It contains the code used.
No results are shown here, so this section can be skipped.


```{r}
#| label: export_abstracts
#| eval: false

corpus_read(corpus_dir) |>
    select(id, doi, ab) |>
    arrow::write_parquet(file.path(".", "data", "tca_corpus", "abstracts_tca.parquet")
```

```{r}
#| label: get_search_term_hits
#|

fn <- file.path(".", "data", "tca_corpus", "search_term_hits.rds")
if (!file.exists(fn)) {
    s_t <- grep("s_1_", names(params), value = TRUE)
    search_term_hits <- parallel::mclapply(
        s_t,
        function(stn) {
            message("getting '", stn, "' ...")
            if (grepl("_f_", stn)) {
                search <- params[[stn]]()
            } else {
                search <- params[[stn]]
            }
            search <- compact(search)
            openalexR::oa_query(filter = list(title_and_abstract.search = search)) |>
                openalexR::oa_request(count_only = TRUE, verbose = TRUE) |>
                unlist()
        },
        mc.cores = params$mc.cores,
        mc.preschedule = FALSE
    ) |>
        do.call(what = cbind) |>
        t() |>
        as.data.frame() |>
        dplyr::mutate(page = NULL, per_page = NULL) |>
        dplyr::mutate(count = formatC(count, format = "f", big.mark = ",", digits = 0))

    rownames(search_term_hits) <- s_t |>
        gsub(pattern = "s_1_", replacement = "") |>
        gsub(pattern = "f_", replacement = "") |>
        gsub(pattern = "^ch", replacement = "Chapter ") |>
        gsub(pattern = "_", replacement = " ")




    saveRDS(search_term_hits, file = fn)
} else {
    search_term_hits <- readRDS(fn)
}
```



```{r}
#| label: get_countries_tca_corpus_data
#|

fn <- file.path(".", "data", "tca_corpus", "countries_tca_corpus.rds")

if (!file.exists(fn)) {
    years <- IPBES.R::corpus_read(corpus_dir) |>
        distinct(publication_year) |>
        collect() |>
        unlist() |>
        as.vector()
    
    if (length(years) > 1) {
        years <- sample(years)
    }

    auth <- pbmcapply::pbmclapply(
        years,
        function(y) {
            authors <- IPBES.R::corpus_read(corpus_dir) |>
                dplyr::filter(publication_year == y) |>
                dplyr::select(author) |>
                collect() |>
                unlist() |>
                IPBES.R::unserialize_arrow()


            data_first <- authors |>
                IPBES.R::extract_countries(first_only = TRUE) |>
                dplyr::group_by(cc) |>
                dplyr::summarise(count = sum(weight)) |>
                rename(
                    iso2c = cc,
                    count_first = count
                )

            data <- authors |>
                IPBES.R::extract_countries(first_only = FALSE) |>
                dplyr::group_by(cc) |>
                dplyr::summarise(count = sum(weight)) |>
                rename(
                    iso2c = cc,
                    count_all = count
                ) |>
                dplyr::full_join(
                    x = data_first,
                    by = "iso2c"
                )

            rm(data_first, authors)

            if (nrow(data) == 0) {
                data$iso3c <- character(0)
            } else {
                data$iso3c <- countrycode::countrycode(
                    data$iso2c,
                    origin = "iso2c",
                    destination = "iso3c"
                )
            }

            data_oa <- openalexR::oa_fetch(
                group_by = "authorships.countries",
                publication_year = y,
                output = "tibble",
                verbose = FALSE
            ) |>
                rename(count_oa = count)

            data_oa$iso3c <- countrycode::countrycode(
                data_oa$key_display_name,
                origin = "country.name",
                destination = "iso3c"
            )

            data_oa <- data_oa |>
                mutate(
                    key_display_name = NULL,
                    key = NULL
                )

            data |>
                mutate(
                    iso2c = NULL
                ) |>
                dplyr::full_join(
                    y = data_oa,
                    by = "iso3c"
                ) |>
                mutate(
                    count_oa = ifelse(is.na(count_oa), 0, count_oa),
                    log_count_oa = log(count_oa + 1),
                    p_oa = count_oa / sum(count_oa),
                    #
                    count_first = ifelse(is.na(count_first), 0, count_first),
                    log_count_first = log(count_first + 1),
                    p_first = count_first / sum(count_first),
                    p_first_output = count_first / count_oa,
                    p_first_diff = (p_oa - p_first) * 100,
                    #
                    count_all = ifelse(is.na(count_all), 0, count_all),
                    log_count_all = log(count_all + 1),
                    p_all = count_all / sum(count_all),
                    p_all_output = count_all / count_oa,
                    p_all_diff = (p_oa - p_all) * 100,
                ) |>
                dplyr::arrange(
                    iso3c
                ) |>
                dplyr::relocate(
                    iso3c,
                    everything()
                )
        },
        mc.cores = params$mc.cores,
        mc.preschedule = FALSE
    )

    names(auth) <- years
    saveRDS(auth, file = fn)
}
```


```{r}
#| label: publications_over_time_data
#|

fn <- file.path(".", "data", "tca_corpus", "publications_over_time_tca_corpus.rds")

if (!file.exists(fn)) {
read_corpus(file.path("data", "tca_corpus", "corpus")) |>
    dplyr::select(publication_year) |>
    dplyr::arrange(publication_year) |>
    dplyr::collect() |>
    table() |>
    as.data.frame() |>
    mutate(
        publication_year = as.integer(as.character(publication_year)),
        p = Freq / sum(Freq),
        p_cum = cumsum(p)
    ) |>
    rename(
        count = Freq
    ) |>
    dplyr::inner_join(
        y = openalexR::oa_fetch(
            search = "",
            group_by = "publication_year",
            output = "tibble",
            verbose = FALSE
        ) |>
            dplyr::select(
                key,
                count
            ) |>
            dplyr::rename(
                publication_year = key,
                count_oa = count
            ) |>
            dplyr::arrange(publication_year) |>
            dplyr::mutate(
                publication_year = as.integer(as.character(publication_year)),
                p_oa = count_oa / sum(count_oa),
                p_oa_cum = cumsum(p_oa)
            )
    )
    saveRDS(data, file = fn)
}
```

```{r}
#| label: get_sample_tca_corpus
#| 

fn <- file.path(".", "data", "tca_corpus", paste0("sample_tca_corpus_", params$sample_size, ".rds"))
fn_df <- file.path(".", "data", "tca_corpus", paste0("sample_tca_corpus_", params$sample_size, ".rds"))
if (!file.exists(fn)) {
    message("Sampling 'transformative change' corpus (n = ", params$sample_size, ") - this can take some time ...")
    sample_tca_corpus <- openalexR::oa_query(
        filter = list(
            title_and_abstract.search = compact(
            paste0(
                "(", params$s_1_transformative_change, ") AND (", params$s_1_nature_environment, ")"
            )
            )
        ),
        options = list(
            sample = params$sample_size
        )
    ) |>
        openalexR::oa_request(count_only = FALSE, verbose = TRUE)

    sample_tca_corpus_df <- oa2df(sample_tca_corpus, entity = "works")

    saveRDS(sample_tca_corpus, file = fn)
    saveRDS(sample_tca_corpus_df, file = fn_df)
} else {
    sample_tca_corpus <- readRDS(fn)
    sample_tca_corpus_df <- readRDS(fn_df)
}
```

```{r}
#| label: prim_topic_tca_corpus
#| eval: true

fn <- file.path(".", "data", "tca_corpus", paste0("prim_topics_tca_corpus.rds"))
if (!file.exists(fn)) {
    # message("Sampling 'transformative change' corpus (n = ", params$sample_size, ") - this can take some time ...")

    prim_topics_tca_corpus <- openalexR::oa_fetch(
        title_and_abstract.search = compact(params$s_1_tca_corpus),
        group_by = "primary_topic.id",
        verbose = FALSE
    )
    names(prim_topics_tca_corpus) <- c("topic_id", "topic_name", "count")
    prim_topics_tca_corpus <- prim_topics_tca_corpus[-2]
    prim_topics_tca_corpus$topic_id <- sub("https://openalex.org/T", "", prim_topics_tca_corpus$topic_id)
    prim_topics_tca_corpus <- merge(
        read.csv(file.path("inputs", "tca_corpus", "OpenAlex_topic_mapping_table - final_topic_field_subfield_table.csv")),
        prim_topics_tca_corpus,
        by = "topic_id"
    )

    prim_topics_tca_corpus <- prim_topics_tca_corpus[order(prim_topics_tca_corpus$count, decreasing = TRUE), ]

    saveRDS(prim_topics_tca_corpus, file = fn)
} else {
    prim_topics_tca_corpus <- readRDS(fn)
}
```


```{r}
#| label: get_key_papers
#|
fn <- file.path(".", "data", "tca_corpus", "key_papers.rds")
if (!file.exists(fn)) {
    key_papers <- lapply(
        params$key_papers,
        function(fn) {
            message("Processing '", fn, "' ...")
            sapply(
                fn,
                function(x) {
                    read.csv(x) |>
                        select(DOI)
                }
            ) |>
                unlist()
        }
    )
    names(key_papers) <- gsub("\\.csv", "", basename(params$key_papers))


    key_papers <- list(
        Ch_1 = unlist(key_papers[grepl("Ch 1 -", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_2 = unlist(key_papers[grepl("Ch 2 -", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_3_Cl_1 = unlist(key_papers[grepl("Ch 3 - Cl1", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_3_Cl_3 = unlist(key_papers[grepl("Ch 3 - Cl3", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_3_Cl_4 = unlist(key_papers[grepl("Ch 3 - Cl4", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_3_Cl_5 = unlist(key_papers[grepl("Ch 3 - Cl5", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_3_Cl_6 = unlist(key_papers[grepl("Ch 3 - Cl6", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_3 = unlist(key_papers[grepl("Ch 3 - p", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_4_Cl_1 = unlist(key_papers[grepl("Ch 4 - Challenge 1", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_4_Cl_2 = unlist(key_papers[grepl("Ch 4 - Challenge 2", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_4_Cl_3 = unlist(key_papers[grepl("Ch 4 - Challenge 3", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_4_Cl_4 = unlist(key_papers[grepl("Ch 4 - Challenge 4", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_4_Cl_5 = unlist(key_papers[grepl("Ch 4 - Challenge 5", names(key_papers))], recursive = FALSE) |> as.vector(),
        Ch_5 = unlist(key_papers[grepl("Ch 5 -", names(key_papers))], recursive = FALSE) |> as.vector()
    )

    saveRDS(key_papers, file = fn)
} else {
    key_papers <- readRDS(fn)
}
```


```{r}
#| label: key_works
#|

fn_kw <- file.path(".", "data", "tca_corpus", "key_works.rds")
fn_kw_df <- file.path(".", "data", "tca_corpus", "key_works_df.rds")
if (!all(file.exists(fn_kw, fn_kw_df))) {
    key_works <- parallel::mclapply(
        key_papers,
        function(kp) {
            dois <- kp[kp != ""] |>
                unlist() |>
                tolower() |>
                unique()

            openalexR::oa_fetch(doi = dois, output = "list")
        },
        mc.cores = params$mc.cores,
        mc.preschedule = FALSE
    )

    found <- sapply(
        key_works,
        function(x) {
            length(x) > 0
        }
    )

    key_works <- key_works[found]

    print("The following key paper sets were excluded as they contained no papers in OpenAlex:\n")
    print(names(found)[!found])

    saveRDS(key_works, file = fn_kw)

    key_works_df <- lapply(
        key_works,
        oa2df,
        entity = "works"
    )

    saveRDS(key_works_df, fn_kw_df)
} else {
    key_works <- readRDS(file = fn_kw)
    key_works_df <- readRDS(fn_kw_df)
}
```




```{r}
#| label: key_works_hits
#|

fn <- file.path(".", "data", "tca_corpus", "key_works_hits.rds")
if (!file.exists(fn)) {
    kws <- key_works_df
    kws$all  <- key_works_df |>
        bind_rows()

    nms <- names(kws)
    key_works_hits <- pbapply::pblapply(
        nms,
        function(nm) {
            message("Getting key paper set for ", nm, " ...")
            dois <- kws[[nm]] |>
                select(doi) |>
                distinct() |>
                unlist() |>
                unique() |>
                tolower()

            s_t <- grep("s_1_", names(params), value = TRUE)
            kw_h <- parallel::mclapply(
                s_t,
                function(stn) {
                    message("  getting '", stn, "' ...")
                    if (grepl("_f_", stn)) {
                        search <- compact(params[[stn]]())
                    } else {
                        search <- compact(params[[stn]])
                    }
                    get_count(dois = dois, list(title_and_abstract.search = search), verbose = FALSE)
                },
                mc.cores = params$mc.cores,
                mc.preschedule = FALSE
            ) |>
                do.call(what = cbind) |>
                as.data.frame()

            names(kw_h) <- s_t

            # if (ncol(kw_h) == 1){
            #     kw_h <- t(kw_h)
            #     rownames(kw_h) <- dois
            # }

            kw_h <- rbind(
                kw_h,
                colSums(kw_h)
            )

            rownames(kw_h)[[nrow(kw_h)]] <- "Total"
            return(kw_h)  
        }
    )

    names(key_works_hits) <- nms

    for (i in nms) {
        # key_works_hits[[i]] <- cbind(
        #     key_works_hits[[i]],
        #     key_works_hits_tca_filtered[[i]]
        # )

        key_works_hits[[i]] <- cbind(
            key_works_hits[[i]],
            Total = rowSums(key_works_hits[[i]])
        ) |>
            mutate(Total = Total - 1) # |>
            # relocate(tca_corpus_SDG, .after = s_1_tca_corpus)
    }

    ###

    saveRDS(key_works_hits, file = fn)
} else {
    key_works_hits <- readRDS(file = fn)
}
```


# Results

## Quality Control
### Number of Hits per Individual Corpus

Here we show the number of hits for the key papers in the different individual corpi. The columns represent the different search terms as defined in @sec-search_terms.

```{r}
#| label: hits_per_search_term_table

dat <- cbind(
    search_term_hits
)

rownames(dat) <- dplyr::recode(
    rownames(dat),
    "transformative change" = "Transformative Change @sec-transform",
    "nature environment" = "Nature @sec-nature",
    "tca corpus" = "Assessment Corpus @sec-tca-corpus",
    "Chapter 1 01" = "Ch1 01 @sec-ch1-01",
    "Chapter 1 02" = "Ch1 02 @sec-ch1-02",
    "Chapter 1 03" = "Ch1 03 @sec-ch1-03",
    "Chapter 1 04" = "Ch1 04 @sec-ch1-04",
    "Chapter 1 05" = "Ch1 05 @sec-ch1-05",
    "Chapter 1 06" = "Ch1 06 @sec-ch1-06",
    "Chapter 2" = "Ch2  @sec-ch2",
    "Chapter 3 01" = "Ch3 01 @sec-ch3-01",
    "Chapter 3 02" = "Ch3 02 @sec-ch3-02",
    "Chapter 3 03" = "Ch3 03 @sec-ch3-03",
    "Chapter 3 04" = "Ch3 04 @sec-ch3-04",
    "Chapter 3 05" = "Ch3 05 @sec-ch3-05",
    "Chapter 3 06" = "Ch3 06 @sec-ch3-06",
    "Chapter 4 01" = "Ch4 01 @sec-ch4-01",
    "Chapter 4 02" = "Ch4 02 @sec-ch4-02",
    "Chapter 5 vision" = "Ch5 Vision @sec-ch5_vision",
    "Chapter 5 vision case" = "Ch5 Vision Case @sec-ch5_vision_case",
    "case" = "Ch5 Case @sec-case"
)

dat |>
    knitr::kable(
        caption = "Number of hits",
    )

rm(dat)
```

### Key papers in different Individual Corpi {#key_papers_in_corpi}


```{r}
#| label: key_paper_hits_in_corpi
#|

tbl <- lapply(
    names(key_works_hits),
    function(n) {
        kwh <- key_works_hits[[n]]
        if (nrow(kwh) > 0) {
            total <- grepl("Total", rownames(kwh))
            rownames(kwh)[!total] <- paste0(n, " - <a href='https://doi.org/", rownames(kwh)[!total], "' target='_blank'>Click here</a>")
            rownames(kwh)[total] <- paste0("**", n, " - Total**")
            kwh |>
                arrange(Total) |>
                apply(
                    c(1, 2),
                    function(x) {
                        ifelse(x == 0, "<font color='red'>0</font>", paste0("<font color='green'>", x, "</font>"))
                    }
                ) |>
                as.data.frame()
        } else {
            return(NULL)
        }
    }
)
tbl <- tbl[sapply(tbl, class) != "NULL"]
tbl <- do.call(what = rbind, tbl)


detail <- rbind(
    "**overall**" = c(
        paste0(
            "**",
            search_term_hits |>
                select(count) |>
                unlist() |>
                as.vector(),
            "**"
        ),
        ""
    ),
    tbl
)

detail <- detail |>
    dplyr::rename(
        "Transformative Change @sec-transform" = s_1_transformative_change,
        "Nature @sec-nature" = s_1_nature_environment,
        "Assessment Corpus @sec-tca-corpus" = s_1_tca_corpus,
        "Ch1 01 @sec-ch1-01" = s_1_ch1_01,
        "Ch1 02 @sec-ch1-02" = s_1_ch1_02,
        "Ch1 03 @sec-ch1-03" = s_1_ch1_03,
        "Ch1 04 @sec-ch1-04" = s_1_ch1_04,
        "Ch1 05 @sec-ch1-05" = s_1_ch1_05,
        "Ch1 06 @sec-ch1-06" = s_1_ch1_06,
        "Ch2  @sec-ch2" = s_1_ch2,
        "Ch3 01 @sec-ch3-01" = s_1_ch3_01,
        "Ch3 02 @sec-ch3-02" = s_1_ch3_02,
        "Ch3 03 @sec-ch3-03" = s_1_ch3_03,
        "Ch3 04 @sec-ch3-04" = s_1_ch3_04,
        "Ch3 05 @sec-ch3-05" = s_1_ch3_05,
        "Ch3 06 @sec-ch3-06" = s_1_ch3_06,
        "Ch4 01 @sec-ch4-01" = s_1_ch4_01,
        "Ch4 02 @sec-ch4-02" = s_1_ch4_02,
        # "Ch5 Vision @sec-ch5_vision" = s_1_ch5_vision,
        "Ch5 Case @sec-case" = s_1_case,
        # "Ch5 Vision Case @sec-ch5_vision_case" = s_1_ch5_vision_case
    )
```

### Key Papers in Individual Corpi

#### Summary
Each column is a different search term, and each row consists of the key papers of a specific chapter and the author who provided the key papers. The number is the number of key papers occurring in the Individual Corpus.
```{r}
in_summary <- grepl("Total|overall", rownames(detail))
knitr::kable(
    detail[in_summary, ]
)
```



#### Detail
```{r}
knitr::kable(
    detail
)
```

## TCA Corpus properties

### Publications over time

The red line is the cumulative proportion of publications, the blue line the cumulative proportion of all of the Op[enAlex corpus. Both use the secondeary (red) axis.

```{r}
#| label: publications_over_time_plot
#|

if (length(list.files(file.path("figures", "tca_corpus"), pattern = "publications_over_time")) < 2) {
    figure <- readRDS(file.path(".", "data", "tca_corpus", "publications_over_time_tca_corpus.rds")) |>
        dplyr::filter(publication_year >= 1900) |>
        ggplot() +
        geom_bar(aes(x = publication_year, y = p), stat = "identity") +
        geom_line(aes(x = publication_year, y = p_cum / 10), color = "red") +
        geom_line(aes(x = publication_year, y = p_oa_cum / 10), color = "blue") +
        scale_x_continuous(breaks = seq(1900, 2020, 10)) +
        scale_y_continuous(
            "Proportion of publications",
            sec.axis = sec_axis(~ . * 10, name = "Cumulative proportion") # divide by 100 to scale back the secondary axis
        ) +
        labs(
            title = "Publications over time",
            x = "Year",
            y = "Number of publications"
        ) +
        theme_minimal() +
        theme(axis.text.y.right = element_text(color = "red"))


    ggplot2::ggsave(
        file.path("figures", "tca_corpus", "publications_over_time.pdf"),
        width = 12,
        height = 6,
        figure
    )
    ggplot2::ggsave(
        file.path("figures", "tca_corpus", "publications_over_time.png"),
        width = 12,
        height = 6,
        figure
    )

    rm(figure)
}
```


![](`r file.path("figures", "tca_corpus", "publications_over_time.png")`)

To download high resolution, [click here](`r file.path("figures", "tca_corpus", "publications_over_time.pdf")`){target="_blank"}

```{r}
data |> IPBES.R::table_dt(fn = "publications_over_time")
rm(data)
```

### Countries in TCA Corpus

The countries are based on the countries of the institutes of all authors, weighted by `1/no_ authors_per_paper`. 

The following calculations were done:

- `**count** = `ifelse(is.na(count), 0, count)`
- `**log_count** = `log(count + 1)`
- `**p** = `count / sum(count)`
- `**count_oa** = `ifelse(is.na(count_oa), 0, count)`
- `**log_count_oa** = `log(count_oa + 1)`
- `**p_oa** = `count_oa / sum(count_oa)`
- `**p_diff** = `(p_oa - p) * 100`
- `**p_ratio** = `count / count_oa`

#### All works

```{r}
#| label: countries_tca_corpus_map
#| fig-width: 18
#| fig-height: 9
#|

data <- countries_tca_corpus |>
    dplyr::full_join(
        openalexR::oa_fetch(
            search = "",
            group_by = "authorships.countries",
            output = "tibble",
            verbose = FALSE
        ) |>
            dplyr::rename(
                count_oa = count,
                country = key_display_name
            ) |>
            dplyr::mutate(
                country = countrycode::countrycode(
                    country,
                    origin = "country.name",
                    destination = "iso2c"
                )
            )
    ) |>
    dplyr::rename(
        count = weight
    ) |>
    dplyr::mutate(
        count = ifelse(is.na(count), 0, count),
        count_scaled = (count - min(count, na.rm = TRUE)) / (max(count, na.rm = TRUE) - min(count, na.rm = TRUE)),
        log_count = log(count + 1),
        p = count / sum(count),
        #
        count_oa = ifelse(is.na(count_oa), 0, count_oa),
        count_oa_scaled = (count - min(count_oa, na.rm = TRUE)) / (max(count_oa, na.rm = TRUE) - min(count_oa, na.rm = TRUE)),
        log_count_oa = log(count_oa + 1),
        p_oa = count_oa / sum(count_oa),
        #
        # p_tca = count / count_oa,
        p_diff = (p_oa - p) * 100,
        p_ratio = (p / p_oa)
    )

data$iso3c <- countrycode::countrycode(
    data$country,
    origin = "iso2c",
    destination = "iso3c"
)


map <- patchwork::wrap_plots(
    #
    data |> map_country_codes(
        map_type = "countries",
        values = "count_oa",
        geodata_path = gdm_dir
    ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", high = "#56B4E9") +
        ggplot2::ggtitle("count of overall publications (count_oa)"),
    ##
    data |> map_country_codes(
        map_type = "countries",
        values = "count",
        geodata_path = gdm_dir
    ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", high = "#56B4E9") +
        ggplot2::ggtitle("count of TCA publications (count_oa)"),
    #
    data |> map_country_codes(
        map_type = "countries",
        values = "log_count_oa",
        geodata_path = gdm_dir
    ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", high = "#56B4E9") +
        ggplot2::ggtitle("log(count + 1) of overall publications (log_count_oa)"),
    ##
    data |> map_country_codes(
        map_type = "countries",
        values = "log_count",
        geodata_path = gdm_dir
    ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", high = "#56B4E9") +
        ggplot2::ggtitle("log(count + 1) of TCA publications (log_count)"),
    #
    data |> map_country_codes(
        map_type = "countries",
        values = "p_oa",
        geodata_path = gdm_dir
    ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", high = "#56B4E9") +
        ggplot2::ggtitle("Overall research output (p_oa = count_oa / sum(count_oa))"),
    #
    data |> map_country_codes(
        map_type = "countries",
        values = "p",
        geodata_path = gdm_dir
    ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", high = "#56B4E9") +
        ggplot2::ggtitle("TCA research output (p = count / sum(count))"),
    #
    data |>
        map_country_codes(
            map_type = "countries",
            values = "p_diff",
            geodata_path = gdm_dir
        ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", high = "#56B4E9") +
        ggplot2::ggtitle("TCA research output (p)"),
    #
    data |>
        map_country_codes(
            map_type = "countries",
            values = "p_ratio",
            geodata_path = gdm_dir
        ) +
        ggplot2::scale_fill_gradient2(low = "#E69F00", mid = "white", high = "#56B4E9", midpoint = 0) +
        ggplot2::ggtitle("ratio output (p / p_oa)"),
    ncol = 2
)

ggplot2::ggsave(
    file.path("maps", "tca_corpus", "publications_countries.pdf"),
    width = 12,
    height = 8,
    map
)
ggplot2::ggsave(
    file.path("maps", "tca_corpus", "publications_countries.png"),
    width = 12,
    height = 8,
    map
)

rm(map)
```


![](`r file.path("maps", "tca_corpus", "publications_countries.png")`)

To download high resolution, [click here](`r file.path("maps", "tca_corpus", "publications_countries.pdf")`){target="_blank"}

```{r}
data |> IPBES.R::table_dt(fn = "publications_per_country")
rm(data)
```

### Topics in corpus

```{r}
#| label: prim_topics_tca_corpus_plot
#|

cs <- cumsum(prim_topics_tca_corpus$count)
cs |>
    plot(
        type = "l",
        xlab = "Topic",
        ylab = "Cumulative Count",
        main = "Cumulative Topics in TCA Corpus"
    )

abline(
    h = 0.95 * cs[length(cs)],
    v = min(which(cs > 0.95 * cs[length(cs)])),
    col = "red"
)

text(
    x = 0.5 * length(cs),
    y = 0.95 * cs[length(cs)],
    pos = 3,
    labels = "95% of the corpus",
    col = "red"
)
```

```{r}
#| label: prim_topics_tca_corpus_table
#|

prim_topics_tca_corpus |>
    relocate(count, .after = "topic_id") |>
    IPBES.R::table_dt(
        fn = "topics_tca_corpus", 
    )    
```

### SubFields in Corpus

```{r}
#| label: prim_subfield_tca_corpus_plot
#|
cs <- prim_topics_tca_corpus |>
    mutate(
        topic_id = NULL,
        topic_name = NULL,
        keywords = NULL,
        summary = NULL,
        wikipedia_url = NULL
    ) |>
    group_by(
        subfield_id,
    ) |>
    summarise(
        count = sum(count)
    ) |>
    arrange(desc(count)) |>
    dplyr::select(count) |>
    unlist() |>
    cumsum()
cs |>
    plot(
        type = "l",
        xlab = "Subfield",
        ylab = "Cumulative Count",
        main = "Cumulative Subfields in TCA Corpus"
    )

abline(
    h = 0.95 * cs[length(cs)],
    v = min(which(cs > 0.95 * cs[length(cs)])),
    col = "red"
)

text(
    x = 0.5 * length(cs),
    y = 0.95 * cs[length(cs)],
    pos = 3,
    labels = "95% of the corpus",
    col = "red"
)
```

```{r}
#| label: prim_subfield_tca_corpus_table
#|

prim_topics_tca_corpus |>
    mutate(
        topic_id = NULL,
        topic_name = NULL,
        keywords = NULL,
        summary = NULL,
        wikipedia_url = NULL
    ) |>
    group_by(
        subfield_id,
        subfield_name,
        field_id,
        field_name,
        domain_id,
        domain_name
    ) |>
    summarise(
        count = sum(count)
    ) |>
    arrange(desc(count)) |>
    relocate(count, .after = "subfield_id") |>
    DT::datatable(
        extensions = c(
            "Buttons",
            "FixedColumns",
            "Scroller"
        ),
        options = list(
            dom = "Bfrtip",
            buttons = list(
                list(
                    extend = "csv",
                    filename = fn
                ),
                list(
                    extend = "excel",
                    filename = fn
                ),
                list(
                    extend = "pdf",
                    filename = fn,
                    orientation = "landscape",
                    customize = DT::JS(
                        "function(doc) {",
                        "  doc.defaultStyle.fontSize = 5;", # Change the font size
                        "}"
                    )
                ),
                "print"
            ),
            scroller = TRUE,
            scrollY = JS("window.innerHeight * 0.7 + 'px'"),
            scrollX = TRUE,
            fixedColumns = list(leftColumns = 4)
        ),
        escape = FALSE
    )
```
<!-- 

# ==== APPENDIX ====


TODO: one search term per chapter with OR
TODO: CH 5 search terms missing - check in emails

TODO: 
- Tranformative
- Nature
- Ch1 01-06 OR 
- Ch2 
- Ch3 01-06 OR
- Ch4 01-02 OR
- Ch5 MISSING (Options?)
- Case-Studies

TODO: which key papers are still missing? -->


- TODO: Histogram / table with topics identified to identify non-relevant papers
